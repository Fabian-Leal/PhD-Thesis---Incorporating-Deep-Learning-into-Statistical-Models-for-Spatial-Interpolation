import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
class DeepKriging(nn.Module):
    def __init__(self, input_size):
        super(DeepKriging, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_size, 100),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.BatchNorm1d(100),
            nn.Linear(100, 100),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(100, 100),
            nn.ReLU(),
            nn.BatchNorm1d(100),
            nn.Linear(100, 1)
        )

    def forward(self, x):
        return self.model(x)

class DeepKrigingTrainer:
    def __init__(self, deposit_data, covariates=None, regular_nn=False, plot_errors=True):
        self.deposit_data = deposit_data
        self.covariates = covariates
        self.phi_columns = self.deposit_data.columns[10:].tolist()
        if regular_nn:
            self.phi_columns = ['X', 'Y', 'Z']
        if self.covariates is not None:
            self.p = len(self.covariates) + len(self.phi_columns)
        else:
            self.p = len(self.phi_columns)
        self.plot_errors = plot_errors
        self.test_mse_list = []
        self.test_mae_list = []
        self.test_adjusted_r2_list = []
        torch.manual_seed(42)
        np.random.seed(42)


    def train_model(self, model, optimizer, criterion):
        self.train_losses = []  # To store training losses during training
        self.test_losses = []   # To store test losses during training
        # Training loop
        for step in range(601):
            pre = model(self.x_train)
            mse = criterion(pre, self.y_train)
            cost = mse

            optimizer.zero_grad()
            cost.backward()
            optimizer.step()

            pre_test = model(self.x_test)
            mse_test = criterion(pre_test, self.y_test)
            self.test_losses.append(mse_test.item())

            self.train_losses.append(mse.item())

        if self.plot_errors:
            plt.figure(figsize=(10, 5))
            plt.plot(self.train_losses, label='Train MSE')
            plt.plot(self.test_losses, label='Test MSE')
            plt.xlabel('Epoch')
            plt.ylabel('MSE')
            plt.title('Training and Test MSE Convergence')
            plt.legend()
            plt.grid(True)
            plt.show()

    def train_neural_network(self, mode="cross", test_size=None):
        if mode == "cross":
            # Define the number of folds for cross-validation
            num_folds = 10
            kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)

            
            # Perform k-fold cross-validation
            for fold, (train_index, test_index) in enumerate(kf.split(self.deposit_data)):
                train_data, test_data = self.deposit_data.iloc[train_index], self.deposit_data.iloc[test_index]

                if self.covariates is not None:
                    self.x_train = torch.tensor(train_data[self.phi_columns + self.covariates].values, dtype=torch.float32)
                    self.x_test = torch.tensor(test_data[self.phi_columns + self.covariates].values, dtype=torch.float32)
                else:
                    self.x_train = torch.tensor(train_data[self.phi_columns].values, dtype=torch.float32)
                    self.x_test = torch.tensor(test_data[self.phi_columns].values, dtype=torch.float32)

                self.y_train = torch.tensor(train_data['Density_gcm3'].values.reshape(-1, 1), dtype=torch.float32)
                self.y_test = torch.tensor(test_data['Density_gcm3'].values.reshape(-1, 1), dtype=torch.float32)

                self.model2 = DeepKriging(self.p)
                criterion = nn.MSELoss()
                optimizer = optim.Adam(self.model2.parameters(), lr=0.005)

                self.train_model(self.model2, optimizer, criterion)
                self.test_predictions_fold = self.model2(self.x_test).detach().numpy().flatten()

                            # Store metrics for this fold
                self.test_predictions_fold = self.model2(self.x_test).detach().numpy().flatten()
                self.test_mse_list.append(mean_squared_error(self.y_test, self.test_predictions_fold))
                self.test_mae_list.append(mean_absolute_error(self.y_test, self.test_predictions_fold))

                y_test_compat = test_data['Density_gcm3'].values

                n = len(y_test_compat)
                mean_y_test = np.mean(y_test_compat)
                sst = np.mean((y_test_compat - mean_y_test) ** 2)
                ssr = np.mean((self.test_predictions_fold - y_test_compat) ** 2)
                r2 = 1 - (ssr / sst)
                adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - self.p - 1))
                self.test_adjusted_r2_list.append(adjusted_r2)

            # Calculate and print average metrics across folds
            print("\nAverage Metrics Across Folds:")
            print(f"  Average MSE: {np.mean(self.test_mse_list):.4f}")
            print(f"  Average MAE: {np.mean(self.test_mae_list):.4f}")
            print(f"  Average Adjusted R2: {np.mean(self.test_adjusted_r2_list):.4f}")

        elif mode == "regular":
            if test_size is None:
                raise ValueError("For regular mode, test_size parameter must be specified.")

            train_data, test_data = train_test_split(self.deposit_data, test_size=test_size, random_state=42)

            if self.covariates is not None:
                self.x_train = torch.tensor(train_data[self.phi_columns + self.covariates].values, dtype=torch.float32)
                self.x_test = torch.tensor(test_data[self.phi_columns + self.covariates].values, dtype=torch.float32)
            else:
                self.x_train = torch.tensor(train_data[self.phi_columns].values, dtype=torch.float32)
                self.x_test = torch.tensor(test_data[self.phi_columns].values, dtype=torch.float32)

            self.y_train = torch.tensor(train_data['Density_gcm3'].values.reshape(-1, 1), dtype=torch.float32)
            self.y_test = torch.tensor(test_data['Density_gcm3'].values.reshape(-1, 1), dtype=torch.float32)

            self.x_train_df = pd.DataFrame(self.x_train.numpy(), columns=self.phi_columns + self.covariates if self.covariates else self.phi_columns)
            self.x_test_df = pd.DataFrame(self.x_test.numpy(), columns=self.phi_columns + self.covariates if self.covariates else self.phi_columns)

            self.model2 = DeepKriging(self.p)
            criterion = nn.MSELoss()
            optimizer = optim.Adam(self.model2.parameters(), lr=0.005)

            self.train_model(self.model2, optimizer, criterion)
            self.test_predictions = self.model2(self.x_test).detach().numpy().flatten()
            self.print_metrics(self.y_test, self.test_predictions, "Deposit Data")

    def print_metrics(self, true_values, predicted_values, dataset_name):
        mse = mean_squared_error(true_values, predicted_values)
        mae = mean_absolute_error(true_values, predicted_values)
        r2 = r2_score(true_values, predicted_values)
        print(f"{dataset_name} MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}")


