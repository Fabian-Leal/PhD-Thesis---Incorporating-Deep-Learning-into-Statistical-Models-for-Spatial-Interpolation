{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D prediction for one hole Kevitsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(2147483648)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_composite_filtered = pd.read_csv(\"Curated_data/two_composite_filtered.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data for each mineral\n",
    "mineral = 'Density_gcm3'\n",
    "two_composite_filtered = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "two_composite_1mineral = two_composite_filtered.dropna(subset=[mineral])\n",
    "\n",
    "np.random.seed(2147483648)\n",
    "\n",
    "# Define the specific hole you want to predict for\n",
    "hole_name = 'KV-NME001'\n",
    "\n",
    "\n",
    "# Filter the data for the selected hole\n",
    "hole_data = two_composite_1mineral[two_composite_1mineral['Name'] == hole_name]\n",
    "\n",
    "# Define the columns to normalize\n",
    "columns_to_normalize = ['X', 'Y', 'Z']  # Add all columns you want to normalize\n",
    "\n",
    "min_values = hole_data[columns_to_normalize].min()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    hole_data[column] = hole_data[column] - min_values[column]\n",
    "\n",
    "# Calculate the minimum and maximum values from the entire dataset\n",
    "min_values = hole_data[columns_to_normalize].min().min()\n",
    "max_values = hole_data[columns_to_normalize].max().max()\n",
    "\n",
    "# Scale the data to (0, 1) using the calculated minimum and maximum values\n",
    "for column in columns_to_normalize:\n",
    "    hole_data[column] = (hole_data[column] - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler to your data and transform the specified columns\n",
    "hole_data.loc[:, [mineral]] = scaler.fit_transform(hole_data.loc[:, [mineral]])\n",
    "\n",
    "\n",
    "\n",
    "# Extract the features (X and Y coordinates) and target (mineral) for the selected hole\n",
    "x = hole_data[['X', 'Z']].values#[:,np.newaxis] makes the second dimension explicit\n",
    "y = hole_data[mineral].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "# Determine the size of the test set (e.g., 20% of the data)\n",
    "test_size = int(0.2 * len(x))\n",
    "\n",
    "# Generate random indices for the test set\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "test_size = int(0.2 * len(x))\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=300, out_features=1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_losses = []  # To store training losses during training\n",
    "test_losses = []   # To store test losses during training\n",
    "\n",
    "for step in range(10000):\n",
    "    pre = model(x_train)\n",
    "    mse = mse_loss(pre, y_train)\n",
    "    cost = mse\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pre_train = model(x_train)\n",
    "    mse_train = mse_loss(pre_train, y_train)\n",
    "    train_losses.append(mse_train.item())\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pre_test = model(x_test)\n",
    "    mse_test = mse_loss(pre_test, y_test)\n",
    "    test_losses.append(mse_test.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f'- Iteration {step}, MSE: {mse.item():.4f}')\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "#plt.ylim(0, 0.5)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.5 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.05 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.025)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.025 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a grid of points for prediction\n",
    "x_grid_hole = np.linspace(x[:, 0].min(), x[:, 0].max(), 100)\n",
    "y_grid_hole = np.linspace(x[:, 1].min(), x[:, 1].max(), 100)\n",
    "xv_hole, yv_hole = np.meshgrid(x_grid_hole, y_grid_hole)\n",
    "xy_grid_hole = np.c_[xv_hole.ravel(), yv_hole.ravel()]\n",
    "\n",
    "# Make predictions for the grid\n",
    "predictions_hole = model(torch.tensor(xy_grid_hole, dtype=torch.float32))\n",
    "\n",
    "# Reshape the predictions to match the grid shape\n",
    "predictions_hole = predictions_hole.data.numpy().reshape(xv_hole.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Pool the values from predictions_hole and y_hole\n",
    "pooled_values = np.concatenate([predictions_hole.ravel(), y.data.numpy()[:, 0]])\n",
    "\n",
    "# Determine the minimum and maximum values for the color mapping\n",
    "vmin = np.min(pooled_values)\n",
    "vmax = np.max(pooled_values)\n",
    "\n",
    "# Create a ScalarMappable for both plots using the same criteria\n",
    "sm = ScalarMappable(cmap='pink_r')\n",
    "sm.set_array([])  # Set an empty array to enforce the same vmin and vmax\n",
    "sm.set_clim(vmin, vmax)  # Set the same vmin and vmax\n",
    "\n",
    "plt.figure(figsize=(8, 14))\n",
    "\n",
    "contour_hole = plt.contourf(xv_hole, yv_hole, predictions_hole, cmap='pink_r', vmin=vmin, vmax=vmax, levels=500)  # Adjust levels as needed\n",
    "scatter = plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), cmap='pink_r', vmin=vmin, vmax=vmax, s=30, label='Selected Hole Data')\n",
    "\n",
    "# Optionally, you can scatter plot the data points for this specific hole\n",
    "\n",
    "# Add a colorbar associated with both plots\n",
    "ax = plt.gca()\n",
    "cb = plt.colorbar(sm, label=mineral, ax=ax)\n",
    "# Set the color mapping based on the scatter plot\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Z')\n",
    "plt.title(f'{mineral} Prediction in 2D for Hole: {hole_name}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data for each mineral\n",
    "\n",
    "mineral = 'Density_gcm3'\n",
    "two_composite_filtered = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "two_composite_1mineral = two_composite_filtered.dropna(subset=[mineral])\n",
    "for hole_name in two_composite_filtered['Name'].unique():\n",
    "    \n",
    "    # Define the specific hole you want to predict for\n",
    "\n",
    "    # Filter the data for the selected hole\n",
    "    hole_data = two_composite_1mineral.loc[two_composite_1mineral['Name'] == hole_name]\n",
    "    if len(hole_data) < 100:\n",
    "        continue\n",
    "    \n",
    "    # Define the columns to normalize\n",
    "    columns_to_normalize = ['X', 'Y', 'Z']  # Add all columns you want to normalize\n",
    "\n",
    "    min_values = hole_data[columns_to_normalize].min()\n",
    "\n",
    "    for column in columns_to_normalize:\n",
    "        hole_data.loc[:, column] = hole_data[column] - min_values[column]\n",
    "\n",
    "    # Calculate the minimum and maximum values from the entire dataset\n",
    "    min_values = hole_data[columns_to_normalize].min().min()\n",
    "    max_values = hole_data[columns_to_normalize].max().max()\n",
    "\n",
    "    # Scale the data to (0, 1) using the calculated minimum and maximum values\n",
    "    for column in columns_to_normalize:\n",
    "        hole_data[column] = (hole_data[column] - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "    # Fit the scaler to your data and transform the specified columns\n",
    "    hole_data.loc[:, [mineral]] = scaler.fit_transform(hole_data.loc[:, [mineral]])\n",
    "\n",
    "    # Extract the features (X and Y coordinates) and target (mineral) for the selected hole\n",
    "    x = hole_data[['X', 'Z']].values#[:,np.newaxis] makes the second dimension explicit\n",
    "    y = hole_data[mineral].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "\n",
    "\n",
    "    # Create train and test sets\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    x = x.to(torch.float32)\n",
    "    y = y.to(torch.float32)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    test_size = int(0.2 * len(x))\n",
    "    test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "    x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "    y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "    x_test = x[np.sort(test_indices)]\n",
    "    y_test = y[np.sort(test_indices)]\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=2, out_features=300),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=300, out_features=1)\n",
    "    )\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    for step in range(5000):\n",
    "        pre = model(x_train)\n",
    "        mse = mse_loss(pre, y_train)\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_train = model(x_train)\n",
    "        mse_train = mse_loss(pre_train, y_train)\n",
    "        train_losses.append(mse_train.item())\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        pre_test = model(x_test)\n",
    "        mse_test = mse_loss(pre_test, y_test)\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(f'- Iteration {step}, MSE: {mse.item():.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Define a grid of points for prediction\n",
    "    x_grid_hole = np.linspace(x[:, 0].min(), x[:, 0].max(), 100)\n",
    "    y_grid_hole = np.linspace(x[:, 1].min(), x[:, 1].max(), 100)\n",
    "    xv_hole, yv_hole = np.meshgrid(x_grid_hole, y_grid_hole)\n",
    "    xy_grid_hole = np.c_[xv_hole.ravel(), yv_hole.ravel()]\n",
    "\n",
    "    # Make predictions for the grid\n",
    "    predictions_hole = model(torch.tensor(xy_grid_hole, dtype=torch.float32))\n",
    "\n",
    "    # Reshape the predictions to match the grid shape\n",
    "    predictions_hole = predictions_hole.data.numpy().reshape(xv_hole.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # Pool the values from predictions_hole and y_hole\n",
    "    pooled_values = np.concatenate([predictions_hole.ravel(), y.data.numpy()[:, 0]])\n",
    "\n",
    "    # Determine the minimum and maximum values for the color mapping\n",
    "    vmin = np.min(pooled_values)\n",
    "    vmax = np.max(pooled_values)\n",
    "\n",
    "    # Create a ScalarMappable for both plots using the same criteria\n",
    "    sm = ScalarMappable(cmap='pink_r')\n",
    "    sm.set_array([])  # Set an empty array to enforce the same vmin and vmax\n",
    "    sm.set_clim(vmin, vmax)  # Set the same vmin and vmax\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create a scatter plot on the left\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.subplot(131)\n",
    "    contour_hole = plt.contourf(xv_hole, yv_hole, predictions_hole, cmap='pink_r', vmin=vmin, vmax=vmax, levels=500)  # Adjust levels as needed\n",
    "    scatter = plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), cmap='pink_r', vmin=vmin, vmax=vmax, s=10, label='Selected Hole Data')\n",
    "\n",
    "    # Optionally, you can scatter plot the data points for this specific hole\n",
    "\n",
    "    # Add a colorbar associated with both plots\n",
    "    ax = plt.gca()\n",
    "    cb = plt.colorbar(sm, label=mineral, ax=ax)\n",
    "    # Set the color mapping based on the scatter plot\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Z')\n",
    "    plt.title(f'{mineral} Prediction in 2D for Hole: {hole_name}')\n",
    "\n",
    "\n",
    "    # Create a layout for the two error plots on the right\n",
    "    plt.subplot(132)\n",
    "    # Create a plot showing only values under 0.2 on the y-axis\n",
    "    plt.plot(train_losses, label='Training', color='blue')\n",
    "    plt.plot(test_losses, label='Test', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    #plt.ylim(0, 0.5)  # Set the y-axis limit to filter values under 0.05\n",
    "    plt.legend()\n",
    "    plt.title('Training and Test Errors Under 0.5 MSE')\n",
    "\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(train_losses, label='Training', color='blue')\n",
    "    plt.plot(test_losses, label='Test', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.ylim(0, 0.025)  # Set the y-axis limit to filter values under 0.05\n",
    "    plt.legend()\n",
    "    plt.title('Training and Test Errors Under 0.025 MSE')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
