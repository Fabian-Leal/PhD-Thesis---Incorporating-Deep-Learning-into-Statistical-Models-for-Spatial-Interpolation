{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D predictions for 1 hole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_composite_filtered = pd.read_csv(\"Curated_data/two_composite_filtered.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "np.random.seed(2147483648)\n",
    "\n",
    "mineral = 'Density_gcm3'\n",
    "hole = 'KV-NME001'\n",
    "two_composite_1mineral = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "two_composite_1mineral = two_composite_1mineral.dropna(subset=[mineral])\n",
    "\n",
    "two_composite_1mineral_1hole = two_composite_1mineral.loc[two_composite_1mineral['Name'] == hole]\n",
    "\n",
    "# Calculate the mean and standard deviation for the mineral column\n",
    "mean_value = two_composite_1mineral_1hole[mineral].mean()\n",
    "std_dev = two_composite_1mineral_1hole[mineral].std()\n",
    "\n",
    "# Define a threshold for values to be removed (4 standard deviations from the mean)\n",
    "threshold = 2 * std_dev\n",
    "\n",
    "# Remove rows where the mineral values are above the threshold\n",
    "two_composite_1mineral_1hole = two_composite_1mineral_1hole[abs(two_composite_1mineral_1hole[mineral] - mean_value) <= threshold]    \n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to your data and transform the specified columns\n",
    "two_composite_1mineral_1hole[['Z', mineral]] = scaler.fit_transform(two_composite_1mineral_1hole[['Z', mineral]])\n",
    "\n",
    "\n",
    "\n",
    "two_composite_1mineral_1hole=two_composite_1mineral_1hole.sort_values(by='Z')\n",
    "\n",
    "x = two_composite_1mineral_1hole[['X','Y', 'Z']].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "y = two_composite_1mineral_1hole[mineral].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "x = x.reshape(len(two_composite_1mineral_1hole),3)\n",
    "x = x[:,2].reshape(-1,1)\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "# Determine the size of the test set (e.g., 20% of the data)\n",
    "test_size = int(0.2 * len(x))\n",
    "\n",
    "# Generate random indices for the test set\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create train and test sets\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "test_size = int(0.2 * len(x))\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=500, out_features=1)\n",
    ")\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "train_losses = []  # To store training losses during training\n",
    "test_losses = []   # To store test losses during training\n",
    "\n",
    "for step in range(4000):\n",
    "    pre = model(x_train)\n",
    "    mse = mse_loss(pre, y_train)\n",
    "    cost = mse\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pre_train = model(x_train)\n",
    "    mse_train = mse_loss(pre_train, y_train)\n",
    "    train_losses.append(mse_train.item())\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pre_test = model(x_test)\n",
    "    mse_test = mse_loss(pre_test, y_test)\n",
    "    test_losses.append(mse_test.item())\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f'- Iteration {step}, MSE: {mse.item():.3f}')\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.2)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.2 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.05 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.05)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.05 MSE')\n",
    "plt.show()\n",
    "\n",
    "# Create a plot showing only values under 0.05 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.025)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.025 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models_result = np.array([model(x_test).detach().numpy() for k in range(1)])\n",
    "\n",
    "models_result = models_result[:, :, 0]\n",
    "models_result = models_result.T\n",
    "mean_values = np.array([models_result[i].mean() for i in range(len(models_result))])\n",
    "std_values = np.array([models_result[i].std() for i in range(len(models_result))])\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(x.data.numpy(), y.data.numpy(), s=4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(x_test.data.numpy()[:,0],y_test.data.numpy()[:,0],'.',color='darkorange',markersize=4,label='Test set')\n",
    "plt.plot(x_train.data.numpy()[:,0],y_train.data.numpy()[:,0],'.',color='green',markersize=4,label='Train set')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(x_test.data.numpy()[:, 0],mean_values,color='navy',lw=3,label='Predicted Mean Model')\n",
    "plt.fill_between(x_test.data.numpy()[:, 0],mean_values-2.0*std_values,mean_values+2.0*std_values,alpha=0.2,color='navy',label='95% confidence interval')\n",
    "\n",
    "\n",
    "\n",
    "#for x_val in x_test.data.numpy()[:, 0]:\n",
    "#    plt.vlines(x_val, ymin=y_test.data.numpy()[:,0].min(), ymax=y_test.data.numpy()[:,0].max(), linestyle='--', color='black', alpha=0.1)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(mineral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mineral = 'Density_gcm3'\n",
    "hole = 'KV-NME001'\n",
    "two_composite_1mineral = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "two_composite_1mineral = two_composite_1mineral.dropna(subset=[mineral])\n",
    "\n",
    "two_composite_1mineral_1hole = two_composite_1mineral.loc[two_composite_1mineral['Name'] == hole]\n",
    "\n",
    "# Calculate the mean and standard deviation for the mineral column\n",
    "mean_value = two_composite_1mineral_1hole[mineral].mean()\n",
    "std_dev = two_composite_1mineral_1hole[mineral].std()\n",
    "\n",
    "# Define a threshold for values to be removed (4 standard deviations from the mean)\n",
    "threshold = 2 * std_dev\n",
    "\n",
    "# Remove rows where the mineral values are above the threshold\n",
    "two_composite_1mineral_1hole = two_composite_1mineral_1hole[abs(two_composite_1mineral_1hole[mineral] - mean_value) <= threshold]    \n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to your data and transform the specified columns\n",
    "two_composite_1mineral_1hole[['Z', mineral]] = scaler.fit_transform(two_composite_1mineral_1hole[['Z', mineral]])\n",
    "\n",
    "\n",
    "\n",
    "two_composite_1mineral_1hole=two_composite_1mineral_1hole.sort_values(by='Z')\n",
    "\n",
    "x = two_composite_1mineral_1hole[['X','Y', 'Z']].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "y = two_composite_1mineral_1hole[mineral].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "x = x.reshape(len(two_composite_1mineral_1hole),3)\n",
    "x = x[:,2].reshape(-1,1)\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "# Determine the size of the test set (e.g., 20% of the data)\n",
    "test_size = int(0.2 * len(x))\n",
    "\n",
    "# Generate random indices for the test set\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "\n",
    "\n",
    "n_splits = 5  # You can choose the number of folds\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a list of colors for each fold\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "mse_train_values = []  # To store training MSE for each fold\n",
    "mse_test_values = []   # To store test MSE for each fold\n",
    "\n",
    "for i, (train_indices, val_indices) in enumerate(kf.split(x)):\n",
    "    x_train_fold = x[train_indices]\n",
    "    y_train_fold = y[train_indices]\n",
    "    x_val_fold = x[val_indices]\n",
    "    y_val_fold = y[val_indices]\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=1, out_features=500),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=500, out_features=1)\n",
    "    )\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    for step in range(10000):\n",
    "        pre = model(x_train_fold)\n",
    "        mse = mse_loss(pre, y_train_fold)\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the training set\n",
    "        pre_train = model(x_train_fold)\n",
    "        mse_train = mse_loss(pre_train, y_train_fold)\n",
    "        train_losses.append(mse_train.item())\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        pre_val = model(x_val_fold)\n",
    "        mse_val = mse_loss(pre_val, y_val_fold)\n",
    "        test_losses.append(mse_val.item())\n",
    "\n",
    "    mse_train_values.append(train_losses)\n",
    "    mse_test_values.append(test_losses)\n",
    "\n",
    "    print(f'Fold {i + 1}:')\n",
    "    print(f'Training MSE: {mse_train.item():.2f}, Test MSE: {mse_val.item():.2f}')\n",
    "\n",
    "# Calculate the mean and standard deviation of training and test MSE values across folds\n",
    "mean_train_mse = np.mean(mse_train_values, axis=0)\n",
    "std_train_mse = np.std(mse_train_values, axis=0)\n",
    "mean_test_mse = np.mean(mse_test_values, axis=0)\n",
    "std_test_mse = np.std(mse_test_values, axis=0)\n",
    "\n",
    "print(f'Cross-validation results:')\n",
    "print(f'Mean Training MSE = {mean_train_mse[-1]:.2f}, Std. Dev. Training MSE = {std_train_mse[-1]:.2f}')\n",
    "print(f'Mean Test MSE = {mean_test_mse[-1]:.2f}, Std. Dev. Test MSE = {std_test_mse[-1]:.2f}')\n",
    "\n",
    "# Create a plot of training and test errors for each fold in the same plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_splits):\n",
    "    plt.plot(range(len(train_losses)), mse_train_values[i], linestyle='-', label=f'Fold {i + 1} - Training', color=colors[i], alpha=0.5)\n",
    "    plt.plot(range(len(test_losses)), mse_test_values[i], linestyle='--', label=f'Fold {i + 1} - Test', color=colors[i], alpha=0.5)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Over Epochs for Each Fold')\n",
    "\n",
    "# Create a plot showing only values lower than 0.03 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_splits):\n",
    "    plt.plot(range(len(train_losses)), mse_train_values[i], linestyle='-', label=f'Fold {i + 1} - Training', color=colors[i], alpha=0.5)\n",
    "    plt.plot(range(len(test_losses)), mse_test_values[i], linestyle='--', label=f'Fold {i + 1} - Test', color=colors[i], alpha=0.5)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.03)  # Set the y-axis limit to filter values under 0.03\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.03 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models_result = np.array([model(x_test).detach().numpy() for k in range(1)])\n",
    "\n",
    "models_result = models_result[:, :, 0]\n",
    "models_result = models_result.T\n",
    "mean_values = np.array([models_result[i].mean() for i in range(len(models_result))])\n",
    "std_values = np.array([models_result[i].std() for i in range(len(models_result))])\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(x.data.numpy(), y.data.numpy(), s=4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(x_test.data.numpy()[:,0],y_test.data.numpy()[:,0],'.',color='darkorange',markersize=4,label='Test set')\n",
    "plt.plot(x_train.data.numpy()[:,0],y_train.data.numpy()[:,0],'.',color='green',markersize=4,label='Train set')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(x_test.data.numpy()[:, 0],mean_values,color='navy',lw=3,label='Predicted Mean Model')\n",
    "plt.fill_between(x_test.data.numpy()[:, 0],mean_values-2.0*std_values,mean_values+2.0*std_values,alpha=0.2,color='navy',label='95% confidence interval')\n",
    "\n",
    "\n",
    "\n",
    "#for x_val in x_test.data.numpy()[:, 0]:\n",
    "#    plt.vlines(x_val, ymin=y_test.data.numpy()[:,0].min(), ymax=y_test.data.numpy()[:,0].max(), linestyle='--', color='black', alpha=0.1)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(mineral)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mineral = 'Density_gcm3'\n",
    "two_composite_1mineral = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "two_composite_1mineral = two_composite_1mineral.dropna(subset=[mineral])\n",
    "for hole in two_composite_filtered['Name'].unique(): \n",
    "    two_composite_1mineral_1hole = two_composite_1mineral.loc[two_composite_1mineral['Name'] == hole]\n",
    "    if len(two_composite_1mineral_1hole) < 100:\n",
    "        continue\n",
    "    \n",
    "    # Calculate the mean and standard deviation for the mineral column\n",
    "    mean_value = two_composite_1mineral_1hole[mineral].mean()\n",
    "    std_dev = two_composite_1mineral_1hole[mineral].std()\n",
    "\n",
    "    # Define a threshold for values to be removed (4 standard deviations from the mean)\n",
    "    threshold = 2 * std_dev\n",
    "\n",
    "    # Remove rows where the mineral values are above the threshold\n",
    "    two_composite_1mineral_1hole = two_composite_1mineral_1hole[abs(two_composite_1mineral_1hole[mineral] - mean_value) <= threshold]    \n",
    "\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to your data and transform the specified columns\n",
    "    two_composite_1mineral_1hole[['Z', mineral]] = scaler.fit_transform(two_composite_1mineral_1hole[['Z', mineral]])\n",
    "\n",
    "\n",
    "\n",
    "    two_composite_1mineral_1hole=two_composite_1mineral_1hole.sort_values(by='Z')\n",
    "\n",
    "    x = two_composite_1mineral_1hole[['X','Y', 'Z']].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "    y = two_composite_1mineral_1hole[mineral].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "    x = x.reshape(len(two_composite_1mineral_1hole),3)\n",
    "    x = x[:,2].reshape(-1,1)\n",
    "\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    x = x.to(torch.float32)\n",
    "    y = y.to(torch.float32)\n",
    "\n",
    "    # Determine the size of the test set (e.g., 20% of the data)\n",
    "    test_size = int(0.2 * len(x))\n",
    "\n",
    "    # Generate random indices for the test set\n",
    "    test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "    # Create train and test sets based on the indices\n",
    "    x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "    y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "    x_test = x[np.sort(test_indices)]\n",
    "    y_test = y[np.sort(test_indices)]\n",
    "\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=200),  \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=200, out_features=1)\n",
    "    )\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for step in range(10000):\n",
    "        pre = model(x_train)\n",
    "        mse = mse_loss(pre, y_train)\n",
    "        cost = mse \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('- Iteration %d, MSE : %2.2f' % (step, mse.item()))\n",
    "    \n",
    "\n",
    "\n",
    "    models_result = np.array([model(x_test).detach().numpy() for k in range(1)])\n",
    "\n",
    "    models_result = models_result[:, :, 0]\n",
    "    models_result = models_result.T\n",
    "    mean_values = np.array([models_result[i].mean() for i in range(len(models_result))])\n",
    "    std_values = np.array([models_result[i].std() for i in range(len(models_result))])\n",
    "\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.scatter(x.data.numpy(), y.data.numpy(), s=4)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.plot(x_test.data.numpy()[:,0],y_test.data.numpy()[:,0],'.',color='darkorange',markersize=4,label='Test set')\n",
    "    plt.plot(x_train.data.numpy()[:,0],y_train.data.numpy()[:,0],'.',color='green',markersize=4,label='Train set')\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(x_test.data.numpy()[:, 0],mean_values,color='navy',lw=3,label='Predicted Mean Model')\n",
    "    plt.fill_between(x_test.data.numpy()[:, 0],mean_values-2.0*std_values,mean_values+2.0*std_values,alpha=0.2,color='navy',label='95% confidence interval')\n",
    "\n",
    "\n",
    "\n",
    "    #for x_val in x_test.data.numpy()[:, 0]:\n",
    "    #    plt.vlines(x_val, ymin=y_test.data.numpy()[:,0].min(), ymax=y_test.data.numpy()[:,0].max(), linestyle='--', color='black', alpha=0.1)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(mineral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define your neural network architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=1, out_features=5),  # Replace with standard Linear layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=5, out_features=1)  # Replace with standard Linear layer\n",
    ")\n",
    "\n",
    "# Create a dummy input tensor\n",
    "dummy_input = torch.randn(1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a SummaryWriter for logging\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Log the model graph to TensorBoard\n",
    "writer.add_graph(model, dummy_input)\n",
    "\n",
    "# Close the SummaryWriter when finished\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"C:\\Users\\23478671\\Github\\PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation\\Paper 3 PhD BNNs for multivariate predictions\" --port 5001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
