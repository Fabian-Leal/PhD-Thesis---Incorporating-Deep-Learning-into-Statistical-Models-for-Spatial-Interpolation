{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy as sp\n",
    "import scipy.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_data = pd.read_csv(\"../Curated_data/final_dataset.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineral = 'Density_gcm3'\n",
    "filter = ['Sulph1_Code', 'Sulph1_Pct', 'Sulph2_Code', 'Sulph2_Pct']\n",
    "deposit_data = density_data\n",
    "\n",
    "deposit_data = deposit_data.dropna(subset=[mineral] + filter)\n",
    "df1 = deposit_data\n",
    "variable=mineral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_composite_1covariates = deposit_data\n",
    "\n",
    "# Calculate the percentage of missing values for each variable\n",
    "missing_percentage = (two_composite_1covariates.isnull().sum() / len(two_composite_1covariates)) * 100\n",
    "\n",
    "# Identify variables with more than 15% missing values\n",
    "variables_to_remove = missing_percentage[missing_percentage > 5].index\n",
    "\n",
    "# Drop the identified variables from the DataFrame\n",
    "two_composite_1covariates = two_composite_1covariates.drop(columns=variables_to_remove)\n",
    "\n",
    "\n",
    "encoded_data = two_composite_1covariates.copy()\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "for column in two_composite_1covariates.columns:\n",
    "    if two_composite_1covariates[column].dtype == 'object':\n",
    "        unique_values = two_composite_1covariates[column].nunique()\n",
    "        \n",
    "        # Check if the number of unique values is within the threshold\n",
    "        if unique_values <= threshold:\n",
    "            # Perform one-hot encoding for columns with unique values within the threshold\n",
    "            encoded_columns = pd.get_dummies(encoded_data[column], prefix=column)\n",
    "            encoded_columns = encoded_columns.astype(int)  # Convert to integers (0 or 1)\n",
    "            encoded_data = pd.concat([encoded_data, encoded_columns], axis=1)\n",
    "            encoded_data = encoded_data.drop(columns=[column])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identify the encoded columns based on the common pattern\n",
    "encoded_columns = [col for col in encoded_data.columns if '_Code_' in col]\n",
    "\n",
    "# List to store the total columns\n",
    "total_columns = []\n",
    "\n",
    "# Iterate through the encoded columns and calculate the total for each category\n",
    "for col in encoded_columns:\n",
    "    # Extract the prefix and original column name\n",
    "    prefix, original_column = col.split('_Code_')\n",
    "    \n",
    "    # Calculate the total for the category\n",
    "    total_column = f\"{original_column}_Total\"\n",
    "    total_columns.append(total_column)\n",
    "    \n",
    "    # Multiply the code column by the corresponding percentage column and sum them\n",
    "    encoded_data[total_column] = (\n",
    "        encoded_data[f\"{prefix}_Code_{original_column}\"] * encoded_data[f\"{prefix}_Pct\"]\n",
    "    )\n",
    "\n",
    "# List to store the total columns\n",
    "total_columns = []\n",
    "\n",
    "# Initialize a dictionary to accumulate totals for each category\n",
    "category_totals = {}\n",
    "\n",
    "# Iterate through the encoded columns and calculate the total for each category\n",
    "for col in encoded_columns:\n",
    "    # Extract the prefix and original column name\n",
    "    prefix, original_column = col.split('_Code_')\n",
    "    \n",
    "    # Calculate the total for the category\n",
    "    total_column = f\"{original_column}_Total\"\n",
    "    if total_column not in total_columns:\n",
    "        total_columns.append(total_column)\n",
    "    \n",
    "    # Multiply the code column by the corresponding percentage column\n",
    "    total_values = encoded_data[f\"{prefix}_Code_{original_column}\"] * encoded_data[f\"{prefix}_Pct\"]\n",
    "    \n",
    "    # Accumulate the totals for each category\n",
    "    if total_column in category_totals:\n",
    "        category_totals[total_column] += total_values\n",
    "    else:\n",
    "        category_totals[total_column] = total_values\n",
    "\n",
    "# Add accumulated totals to the DataFrame\n",
    "for total_column, total_values in category_totals.items():\n",
    "    encoded_data[total_column] = total_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = ['Sc_ppm',\n",
    " 'Al_pct',\n",
    " 'Y_ppm',\n",
    " 'V_ppm',\n",
    " 'Sr_ppm',\n",
    " 'Ca_pct',\n",
    " 'P_ppm',\n",
    " 'Si_pct',\n",
    " 'Li_ppm',\n",
    " 'Mg_pct',\n",
    " 'La_ppm',\n",
    " 'RQD_Pct',\n",
    " 'Alt1_Int_wk',\n",
    " 'Ba_ppm',\n",
    " 'Sulph1_Code_PO',\n",
    " 'IP_pct',\n",
    " 'Sulph2_Code_CP',\n",
    " 'Sulph2_Code_PO',\n",
    " 'X',\n",
    " 'PY_Total',\n",
    " 'Z',\n",
    " 'PO_Total',\n",
    " 'CP_Total',\n",
    " 'Cr_ppm',\n",
    " 'B_ppm',\n",
    " 'Y',\n",
    " 'Sb_ppm',\n",
    " 'Weathering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density_gcm3</th>\n",
       "      <th>RQD_Pct</th>\n",
       "      <th>Cr_ppm</th>\n",
       "      <th>CP_Total</th>\n",
       "      <th>PO_Total</th>\n",
       "      <th>PY_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498922.13</td>\n",
       "      <td>7511747.51</td>\n",
       "      <td>148.80</td>\n",
       "      <td>3.13</td>\n",
       "      <td>88.00</td>\n",
       "      <td>212.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498922.68</td>\n",
       "      <td>7511747.45</td>\n",
       "      <td>146.88</td>\n",
       "      <td>3.15</td>\n",
       "      <td>88.00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498945.16</td>\n",
       "      <td>7511745.25</td>\n",
       "      <td>70.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498945.73</td>\n",
       "      <td>7511745.20</td>\n",
       "      <td>68.22</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498946.29</td>\n",
       "      <td>7511745.15</td>\n",
       "      <td>66.30</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81071</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.52</td>\n",
       "      <td>7510618.17</td>\n",
       "      <td>85.03</td>\n",
       "      <td>3.44</td>\n",
       "      <td>92.35</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81072</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.32</td>\n",
       "      <td>7510617.19</td>\n",
       "      <td>83.30</td>\n",
       "      <td>3.43</td>\n",
       "      <td>92.35</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81073</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.13</td>\n",
       "      <td>7510616.22</td>\n",
       "      <td>81.56</td>\n",
       "      <td>3.44</td>\n",
       "      <td>85.84</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81074</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499346.93</td>\n",
       "      <td>7510615.24</td>\n",
       "      <td>79.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>85.84</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81075</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499346.74</td>\n",
       "      <td>7510614.27</td>\n",
       "      <td>78.09</td>\n",
       "      <td>3.41</td>\n",
       "      <td>85.84</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name           X           Y       Z  Density_gcm3  RQD_Pct  \\\n",
       "393    KV-NME001  3498922.13  7511747.51  148.80          3.13    88.00   \n",
       "394    KV-NME001  3498922.68  7511747.45  146.88          3.15    88.00   \n",
       "434    KV-NME001  3498945.16  7511745.25   70.14          3.22    99.00   \n",
       "435    KV-NME001  3498945.73  7511745.20   68.22          3.22    99.00   \n",
       "436    KV-NME001  3498946.29  7511745.15   66.30          3.22    99.00   \n",
       "...          ...         ...         ...     ...           ...      ...   \n",
       "81071      KV365  3499347.52  7510618.17   85.03          3.44    92.35   \n",
       "81072      KV365  3499347.32  7510617.19   83.30          3.43    92.35   \n",
       "81073      KV365  3499347.13  7510616.22   81.56          3.44    85.84   \n",
       "81074      KV365  3499346.93  7510615.24   79.83          3.40    85.84   \n",
       "81075      KV365  3499346.74  7510614.27   78.09          3.41    85.84   \n",
       "\n",
       "       Cr_ppm  CP_Total  PO_Total  PY_Total  \n",
       "393     212.6       1.0       1.0       0.0  \n",
       "394     268.0       1.0       1.0       0.0  \n",
       "434     215.0       1.0       1.0       0.0  \n",
       "435     236.0       1.5       2.0       0.0  \n",
       "436     256.0       2.0       3.0       0.0  \n",
       "...       ...       ...       ...       ...  \n",
       "81071   131.0       0.2       3.0       0.0  \n",
       "81072   125.0       0.2       3.0       0.0  \n",
       "81073   128.0       0.2       3.0       0.0  \n",
       "81074   129.0       0.2       3.0       0.0  \n",
       "81075   130.0       0.2       3.0       0.0  \n",
       "\n",
       "[2618 rows x 10 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_encoded_data = encoded_data[encoded_data.columns.intersection(variable_names+ ['Density_gcm3', 'Name'])]\n",
    "\n",
    "deposit_data = encoded_data[['Name', 'X', 'Y', 'Z', 'Density_gcm3', 'RQD_Pct', 'Cr_ppm', 'CP_Total',\n",
    "       'PO_Total', 'PY_Total']]\n",
    "total_columns = ['CP_Total','PO_Total', 'PY_Total']\n",
    "\n",
    "#all covariates\n",
    "covariates = total_columns[:3] + ['RQD_Pct', 'Cr_ppm']\n",
    "#sulphides only\n",
    "#covariates = total_columns[:3] \n",
    "#No covariates, only spatial\n",
    "#covariates = []\n",
    "\n",
    "deposit_data.describe()\n",
    "deposit_data.fillna(0, inplace=True)\n",
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to normalize\n",
    "columns_to_normalize = ['X', 'Y', 'Z']   # Add all columns you want to normalize\n",
    "\n",
    "min_values = deposit_data[columns_to_normalize].min()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = deposit_data[column] - min_values[column]\n",
    "\n",
    "# Calculate the minimum and maximum values from the entire dataset\n",
    "min_values = deposit_data[columns_to_normalize].min().min()\n",
    "max_values = deposit_data[columns_to_normalize].max().max()\n",
    "\n",
    "# Scale the data to (0, 1) using the calculated minimum and maximum values\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = (deposit_data[column] - min_values) / (max_values - min_values)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "deposit_data.loc[:, [mineral] +covariates] = scaler.fit_transform(deposit_data.loc[:,[mineral] + covariates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lon = df1.values[:,4]\n",
    "# lat = df1.values[:,5]\n",
    "# az = df1.values[:,6]\n",
    "\n",
    "# normalized_lon = (lon-min(lon))/(max(lon)-min(lon))\n",
    "# normalized_lat = (lat-min(lat))/(max(lat)-min(lat))\n",
    "# normalized_az = (az-min(az))/(max(az)-min(az))\n",
    "# N = lon.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Lon: [0.43781378776682156 0.43806121898106964 0.4481744075146454 ...\n",
      " 0.6290106350432114 0.6289206600563835 0.6288351838188028]\n",
      "Normalized Lat: [0.5098162710765618 0.5097892785806601 0.5087995537240868 ...\n",
      " 0.0008772561228813492 0.0004363786870266015 0.0]\n",
      "Normalized Az: [0.46145471558890383 0.4605909557141493 0.42606755322005485 ...\n",
      " 0.4312051249751051 0.43042684133795656 0.4296440589514603]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lon = df1.values[:, 4]\n",
    "lat = df1.values[:, 5]\n",
    "az = df1.values[:, 6]\n",
    "\n",
    "# Subtract the minimum values for each array\n",
    "lon = lon - np.min(lon)\n",
    "lat = lat - np.min(lat)\n",
    "az = az - np.min(az)\n",
    "\n",
    "# Calculate the overall minimum and maximum values from the entire dataset\n",
    "min_value = np.min([np.min(lon), np.min(lat), np.min(az)])\n",
    "max_value = np.max([np.max(lon), np.max(lat), np.max(az)])\n",
    "\n",
    "# Scale the arrays to (0, 1) using the calculated minimum and maximum values\n",
    "normalized_lon = (lon - min_value) / (max_value - min_value)\n",
    "normalized_lat = (lat - min_value) / (max_value - min_value)\n",
    "normalized_az = (az - min_value) / (max_value - min_value)\n",
    "\n",
    "N = lon.shape[0]\n",
    "\n",
    "# Display the normalized arrays\n",
    "print(\"Normalized Lon:\", normalized_lon)\n",
    "print(\"Normalized Lat:\", normalized_lat)\n",
    "print(\"Normalized Az:\", normalized_az)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_basis = [10**3,19**3,37**3]\n",
    "knots_1dx = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dy = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dz = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "\n",
    "\n",
    "##Wendland kernel\n",
    "basis_size = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/(num_basis[res]**(1/3))*2.5\n",
    "    knots_x, knots_y, knots_z = np.meshgrid(knots_1dx[res],knots_1dy[res], knots_1dz[res])\n",
    "    knots = np.column_stack((knots_x.flatten(),knots_y.flatten(),knots_z.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(np.vstack((normalized_lon,normalized_lat, normalized_az)).astype(float).T-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + basis_size] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + basis_size] = 0\n",
    "    basis_size = basis_size + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2618, 58512)\n",
      "(2618, 6403)\n"
     ]
    }
   ],
   "source": [
    "## Romove the all-zero columns\n",
    "idx_zero = np.array([], dtype=int)\n",
    "for i in range(phi.shape[1]):\n",
    "    if sum(phi[:,i]!=0)==0:\n",
    "        idx_zero = np.append(idx_zero,int(i))\n",
    "\n",
    "phi_reduce = np.delete(phi,idx_zero,1)\n",
    "print(phi.shape)\n",
    "print(phi_reduce.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      phi_0  phi_1  phi_2  phi_3  phi_4  phi_5  phi_6     phi_7     phi_8  \\\n",
      "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "...     ...    ...    ...    ...    ...    ...    ...       ...       ...   \n",
      "2613    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000246  0.003618   \n",
      "2614    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000262  0.003631   \n",
      "2615    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000279  0.003641   \n",
      "2616    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000297  0.003651   \n",
      "2617    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000315  0.003659   \n",
      "\n",
      "         phi_9  ...  phi_6393  phi_6394  phi_6395  phi_6396  phi_6397  \\\n",
      "0     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "1     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "3     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "4     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "2613  0.000032  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2614  0.000029  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2615  0.000027  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2616  0.000025  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2617  0.000023  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "      phi_6398  phi_6399  phi_6400  phi_6401  phi_6402  \n",
      "0          0.0       0.0       0.0       0.0       0.0  \n",
      "1          0.0       0.0       0.0       0.0       0.0  \n",
      "2          0.0       0.0       0.0       0.0       0.0  \n",
      "3          0.0       0.0       0.0       0.0       0.0  \n",
      "4          0.0       0.0       0.0       0.0       0.0  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "2613       0.0       0.0       0.0       0.0       0.0  \n",
      "2614       0.0       0.0       0.0       0.0       0.0  \n",
      "2615       0.0       0.0       0.0       0.0       0.0  \n",
      "2616       0.0       0.0       0.0       0.0       0.0  \n",
      "2617       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[2618 rows x 6403 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_phi = np.shape(phi_reduce)[1]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(phi_reduce, columns=[f'phi_{i}' for i in range(len_phi)])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density_gcm3</th>\n",
       "      <th>RQD_Pct</th>\n",
       "      <th>Cr_ppm</th>\n",
       "      <th>CP_Total</th>\n",
       "      <th>PO_Total</th>\n",
       "      <th>PY_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>phi_6393</th>\n",
       "      <th>phi_6394</th>\n",
       "      <th>phi_6395</th>\n",
       "      <th>phi_6396</th>\n",
       "      <th>phi_6397</th>\n",
       "      <th>phi_6398</th>\n",
       "      <th>phi_6399</th>\n",
       "      <th>phi_6400</th>\n",
       "      <th>phi_6401</th>\n",
       "      <th>phi_6402</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.437814</td>\n",
       "      <td>0.509816</td>\n",
       "      <td>0.461455</td>\n",
       "      <td>0.400922</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.127305</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.438061</td>\n",
       "      <td>0.509789</td>\n",
       "      <td>0.460591</td>\n",
       "      <td>0.410138</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.160479</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448174</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.426068</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.128743</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448431</td>\n",
       "      <td>0.508777</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.141317</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448683</td>\n",
       "      <td>0.508755</td>\n",
       "      <td>0.424340</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.153293</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629186</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.432766</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629096</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.431988</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629011</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.076647</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.628921</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.430427</td>\n",
       "      <td>0.525346</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.628835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429644</td>\n",
       "      <td>0.529954</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.077844</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows × 6413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name         X         Y         Z  Density_gcm3  RQD_Pct  \\\n",
       "0     KV-NME001  0.437814  0.509816  0.461455      0.400922   0.8800   \n",
       "1     KV-NME001  0.438061  0.509789  0.460591      0.410138   0.8800   \n",
       "2     KV-NME001  0.448174  0.508800  0.426068      0.442396   0.9900   \n",
       "3     KV-NME001  0.448431  0.508777  0.425204      0.442396   0.9900   \n",
       "4     KV-NME001  0.448683  0.508755  0.424340      0.442396   0.9900   \n",
       "...         ...       ...       ...       ...           ...      ...   \n",
       "2613      KV365  0.629186  0.001755  0.432766      0.543779   0.9235   \n",
       "2614      KV365  0.629096  0.001314  0.431988      0.539171   0.9235   \n",
       "2615      KV365  0.629011  0.000877  0.431205      0.543779   0.8584   \n",
       "2616      KV365  0.628921  0.000436  0.430427      0.525346   0.8584   \n",
       "2617      KV365  0.628835  0.000000  0.429644      0.529954   0.8584   \n",
       "\n",
       "        Cr_ppm  CP_Total  PO_Total  PY_Total  ...  phi_6393  phi_6394  \\\n",
       "0     0.127305     0.250  0.066667       0.0  ...       0.0       0.0   \n",
       "1     0.160479     0.250  0.066667       0.0  ...       0.0       0.0   \n",
       "2     0.128743     0.250  0.066667       0.0  ...       0.0       0.0   \n",
       "3     0.141317     0.375  0.133333       0.0  ...       0.0       0.0   \n",
       "4     0.153293     0.500  0.200000       0.0  ...       0.0       0.0   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "2613  0.078443     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2614  0.074850     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2615  0.076647     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2616  0.077246     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2617  0.077844     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "\n",
       "      phi_6395  phi_6396  phi_6397  phi_6398  phi_6399  phi_6400  phi_6401  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2613       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2614       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2615       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2616       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2617       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      phi_6402  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "2613       0.0  \n",
       "2614       0.0  \n",
       "2615       0.0  \n",
       "2616       0.0  \n",
       "2617       0.0  \n",
       "\n",
       "[2618 rows x 6413 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reset = df.reset_index(drop=True)\n",
    "deposit_data_reset = deposit_data.reset_index(drop=True)\n",
    "\n",
    "# Concatenate along columns\n",
    "deposit_data = pd.concat([deposit_data_reset, df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phi_0', 'phi_1', 'phi_2', 'phi_3', 'phi_4', 'phi_5', 'phi_6', 'phi_7', 'phi_8', 'phi_9']\n"
     ]
    }
   ],
   "source": [
    "# Assuming deposit_data is your DataFrame\n",
    "# Extract the names of the first 98 columns\n",
    "phi_columns = deposit_data.columns[10:].tolist()\n",
    "\n",
    "# Display the list of column names\n",
    "print(phi_columns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data = deposit_data.dropna(subset=['Density_gcm3'] + covariates + phi_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Iteration 0, MSE: 0.5459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [65], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m cost \u001b[38;5;241m=\u001b[39m mse\n\u001b[0;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 70\u001b[0m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     73\u001b[0m pre_train \u001b[38;5;241m=\u001b[39m model(x_train)\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p = len(phi_columns) + len(covariates)\n",
    "\n",
    "x = deposit_data[phi_columns + covariates].values #[:,np.newaxis] makes the second dimension explicit\n",
    "y = deposit_data[[variable]].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "x = x.reshape(len(deposit_data),p)\n",
    "x = x[:,[i for i in range(p)]]\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "\n",
    "# Determine the size of the test set (e.g., 20% of the data)\n",
    "test_size = int(0.2 * len(x))\n",
    "\n",
    "# Generate random indices for the test set\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(in_features=p, out_features=1000),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(in_features=1000, out_features=1)\n",
    "# )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=p, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5) ,\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(in_features=100, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=100, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "#Apparently lr=0.005 is better than 0.01 and than 0.001: quicker and better convergence\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []  # To store training losses during training\n",
    "test_losses = []   # To store test losses during training\n",
    "\n",
    "for step in range(601):\n",
    "    pre = model(x_train)\n",
    "    mse = mse_loss(pre, y_train)\n",
    "    cost = mse\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pre_train = model(x_train)\n",
    "    mse_train = mse_loss(pre_train, y_train)\n",
    "    train_losses.append(mse_train.item())\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pre_test = model(x_test)\n",
    "    mse_test = mse_loss(pre_test, y_test)\n",
    "    test_losses.append(mse_test.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f'- Iteration {step}, MSE: {mse.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "#plt.ylim(0, 0.5)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.5 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.04)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.2 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST DEEPKRIGING NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [71], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m cost \u001b[38;5;241m=\u001b[39m mse\n\u001b[0;32m     75\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 76\u001b[0m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     79\u001b[0m pre_test \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(x_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gftg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS W the 2 covaraites, no suplhides\n",
    "\\\n",
    "Average Metrics Across Folds:\n",
    "\\\n",
    "  Average MSE: 0.0033 \n",
    "  \\\n",
    "  Average MAE: 0.0403 \n",
    "  \\\n",
    "  STD MAE: 0.0027\n",
    "  \\\n",
    "  STD MSE: 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS W THE 5 covariates, WITH sulphides:\n",
    "\\\n",
    "Average Metrics Across Folds:\n",
    "\\\n",
    "  Average MSE: 0.0031\n",
    "  \\\n",
    "  Average MAE: 0.0392\n",
    "  \\\n",
    "  STD MAE: 0.0028\n",
    "  \\\n",
    "  STD MSE: 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS W THE 5 covariates, WITH sulphides AND normalising to keep distances:\n",
    "\\\n",
    "Average Metrics Across Folds:\n",
    "\\\n",
    "  Average MSE: 0.0031\n",
    "  \\\n",
    "  Average MAE: 0.0392\n",
    "  \\\n",
    "  STD MAE: 0.0028\n",
    "  \\\n",
    "  STD MSE: 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # Function to print evaluation metrics\n",
    "# def print_metrics(actual, predicted, set_name):\n",
    "#     mse = mean_squared_error(actual, predicted)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(actual, predicted)\n",
    "#     r2 = r2_score(actual, predicted)\n",
    "\n",
    "#     print(f\"Metrics for {set_name} set:\")\n",
    "#     print(f\"  MSE: {mse:.4f}\")\n",
    "#     print(f\"  RMSE: {rmse:.4f}\")\n",
    "#     print(f\"  MAE: {mae:.4f}\")\n",
    "#     print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# # Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# # Create an array to store metrics for each fold\n",
    "# test_mse_list = []\n",
    "# test_mae_list = []\n",
    "# test_r2_list = []\n",
    "\n",
    "# # Define the number of folds for cross-validation\n",
    "# num_folds = 10\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# # Define a neural network with separate branches for phi_columns and covariates\n",
    "# class GroupedNet(nn.Module):\n",
    "#     def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "#         super(GroupedNet, self).__init__()\n",
    "#         self.phi_branch = nn.Sequential(\n",
    "#             nn.Linear(in_features=input_size_phi, out_features=100),\n",
    "#             nn.Linear(in_features=100, out_features=1)\n",
    "     \n",
    "#         )\n",
    "#         self.covariates_branch = nn.Sequential(\n",
    "#             nn.Linear(in_features=input_size_covariates, out_features=100),\n",
    "#             nn.Linear(in_features=100, out_features=1)       \n",
    "#           )\n",
    "        \n",
    "#         self.combine_layer = nn.Sequential(\n",
    "#             nn.Linear(2, 100), \n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.BatchNorm1d(100),\n",
    "#             nn.Linear(in_features=100, out_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(in_features=100, out_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(100),\n",
    "#             nn.Linear(in_features=100, out_features=1)\n",
    "#         )\n",
    "                                           \n",
    "\n",
    "#     def forward(self, input_phi, input_covariates):\n",
    "#         phi_output = self.phi_branch(input_phi)\n",
    "#         covariates_output = self.covariates_branch(input_covariates)\n",
    "#         x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "#         output = self.combine_layer(x)\n",
    "#         return output\n",
    "\n",
    "# # Perform k-fold cross-validation\n",
    "# for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "#     train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "#     x_train_phi = train_data[phi_columns].values\n",
    "#     x_train_covariates = train_data[covariates].values\n",
    "#     y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "#     x_test_phi = test_data[phi_columns].values\n",
    "#     x_test_covariates = test_data[covariates].values\n",
    "#     y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "#     # Define your neural network\n",
    "#     model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "#     mse_loss = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#     train_losses = []  # To store training losses during training\n",
    "#     test_losses = []   # To store test losses during training\n",
    "\n",
    "#     # Training loop\n",
    "#     for step in range(601):\n",
    "#         pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "#         mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "#         cost = mse\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "#         mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "#         test_losses.append(mse_test.item())\n",
    "\n",
    "#     # Store metrics for this fold\n",
    "#     test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "#     test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "#     test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "#     test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "#     # Print metrics for the current fold\n",
    "#     print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "#     print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# # Print average\n",
    "# # Print average metrics across folds\n",
    "# print(\"\\nAverage Metrics Across Folds:\")\n",
    "# print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "# print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "# print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "# print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "# print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "# print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST MODIFIED (Deepkriging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0595\n",
      "  MAE: 0.0386\n",
      "  R^2: 0.7782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0038\n",
      "  RMSE: 0.0614\n",
      "  MAE: 0.0421\n",
      "  R^2: 0.7122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0030\n",
      "  RMSE: 0.0550\n",
      "  MAE: 0.0380\n",
      "  R^2: 0.7948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0024\n",
      "  RMSE: 0.0494\n",
      "  MAE: 0.0377\n",
      "  R^2: 0.8191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0042\n",
      "  RMSE: 0.0651\n",
      "  MAE: 0.0456\n",
      "  R^2: 0.7641\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0036\n",
      "  RMSE: 0.0596\n",
      "  MAE: 0.0431\n",
      "  R^2: 0.7204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0036\n",
      "  RMSE: 0.0603\n",
      "  MAE: 0.0408\n",
      "  R^2: 0.7985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0590\n",
      "  MAE: 0.0421\n",
      "  R^2: 0.8068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0049\n",
      "  RMSE: 0.0702\n",
      "  MAE: 0.0462\n",
      "  R^2: 0.6107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0042\n",
      "  RMSE: 0.0647\n",
      "  MAE: 0.0459\n",
      "  R^2: 0.7870\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0037\n",
      "  Average MAE: 0.0420\n",
      "  Average R2: 0.7592\n",
      "  STD MSE: 0.0006\n",
      "  STD MAE: 0.0031\n",
      "  STD R2: 0.0596\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network with separate branches for phi_columns and covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "     \n",
    "        )\n",
    "        self.covariates_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_covariates, out_features=1)      \n",
    "          )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(2, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "                                           \n",
    "\n",
    "    def forward(self, input_phi, input_covariates):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        covariates_output = self.covariates_branch(input_covariates)\n",
    "        x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    x_train_covariates = train_data[covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    x_test_covariates = test_data[covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0132\n",
      "  RMSE: 0.1150\n",
      "  MAE: 0.0706\n",
      "  R^2: 0.1708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0140\n",
      "  RMSE: 0.1185\n",
      "  MAE: 0.0804\n",
      "  R^2: -0.0707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0127\n",
      "  RMSE: 0.1127\n",
      "  MAE: 0.0688\n",
      "  R^2: 0.1377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0123\n",
      "  RMSE: 0.1108\n",
      "  MAE: 0.0702\n",
      "  R^2: 0.0900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0180\n",
      "  RMSE: 0.1342\n",
      "  MAE: 0.0832\n",
      "  R^2: -0.0007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0120\n",
      "  RMSE: 0.1094\n",
      "  MAE: 0.0780\n",
      "  R^2: 0.0599\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0188\n",
      "  RMSE: 0.1372\n",
      "  MAE: 0.0859\n",
      "  R^2: -0.0429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0191\n",
      "  RMSE: 0.1382\n",
      "  MAE: 0.0910\n",
      "  R^2: -0.0608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0127\n",
      "  RMSE: 0.1125\n",
      "  MAE: 0.0782\n",
      "  R^2: 0.0016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0190\n",
      "  RMSE: 0.1380\n",
      "  MAE: 0.0869\n",
      "  R^2: 0.0326\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0152\n",
      "  Average MAE: 0.0793\n",
      "  Average R2: 0.0318\n",
      "  STD MSE: 0.0030\n",
      "  STD MAE: 0.0073\n",
      "  STD R2: 0.0783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network with separate branches for phi_columns and covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "     \n",
    "        )\n",
    "        self.covariates_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_covariates, out_features=1)      \n",
    "          )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(2, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "                                           \n",
    "\n",
    "    def forward(self, input_phi, input_covariates):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        covariates_output = self.covariates_branch(input_covariates)\n",
    "        x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    x_train_covariates = train_data[covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    x_test_covariates = test_data[covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepkriging no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0142\n",
      "  RMSE: 0.1191\n",
      "  MAE: 0.0762\n",
      "  R^2: 0.1108\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0134\n",
      "  RMSE: 0.1156\n",
      "  MAE: 0.0771\n",
      "  R^2: -0.0197\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0147\n",
      "  RMSE: 0.1211\n",
      "  MAE: 0.0784\n",
      "  R^2: 0.0049\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0131\n",
      "  RMSE: 0.1143\n",
      "  MAE: 0.0756\n",
      "  R^2: 0.0319\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0181\n",
      "  RMSE: 0.1344\n",
      "  MAE: 0.0844\n",
      "  R^2: -0.0050\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0124\n",
      "  RMSE: 0.1114\n",
      "  MAE: 0.0744\n",
      "  R^2: 0.0239\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0184\n",
      "  RMSE: 0.1358\n",
      "  MAE: 0.0853\n",
      "  R^2: -0.0210\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0180\n",
      "  RMSE: 0.1341\n",
      "  MAE: 0.0846\n",
      "  R^2: 0.0012\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0126\n",
      "  RMSE: 0.1124\n",
      "  MAE: 0.0733\n",
      "  R^2: 0.0039\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0177\n",
      "  RMSE: 0.1330\n",
      "  MAE: 0.0824\n",
      "  R^2: 0.1008\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0153\n",
      "  Average MAE: 0.0792\n",
      "  Average R2: 0.0232\n",
      "  STD MSE: 0.0024\n",
      "  STD MAE: 0.0043\n",
      "  STD R2: 0.0442\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, phi_columns, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network without covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "        )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(1, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_phi):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        x = phi_output\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network without covariates\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437814</td>\n",
       "      <td>0.509816</td>\n",
       "      <td>0.461455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438061</td>\n",
       "      <td>0.509789</td>\n",
       "      <td>0.460591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.448174</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.426068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448431</td>\n",
       "      <td>0.508777</td>\n",
       "      <td>0.425204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.448683</td>\n",
       "      <td>0.508755</td>\n",
       "      <td>0.424340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>0.629186</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.432766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>0.629096</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.431988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>0.629011</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.431205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0.628921</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.430427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>0.628835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X         Y         Z\n",
       "0     0.437814  0.509816  0.461455\n",
       "1     0.438061  0.509789  0.460591\n",
       "2     0.448174  0.508800  0.426068\n",
       "3     0.448431  0.508777  0.425204\n",
       "4     0.448683  0.508755  0.424340\n",
       "...        ...       ...       ...\n",
       "2613  0.629186  0.001755  0.432766\n",
       "2614  0.629096  0.001314  0.431988\n",
       "2615  0.629011  0.000877  0.431205\n",
       "2616  0.628921  0.000436  0.430427\n",
       "2617  0.628835  0.000000  0.429644\n",
       "\n",
       "[2618 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deposit_data[['X','Y','Z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deposit_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Perform k-fold cross-validation\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(\u001b[43mdeposit_data\u001b[49m)):\n\u001b[0;32m     67\u001b[0m     train_data, test_data \u001b[38;5;241m=\u001b[39m deposit_data\u001b[38;5;241m.\u001b[39miloc[train_index], deposit_data\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     69\u001b[0m     x_train_phi \u001b[38;5;241m=\u001b[39m train_data[phi_columns]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mNameError\u001b[0m: name 'deposit_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, phi_columns, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network without covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "        )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(1, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_phi):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        x = phi_output\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network without covariates\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
