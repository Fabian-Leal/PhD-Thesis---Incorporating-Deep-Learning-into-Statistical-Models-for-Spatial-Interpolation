{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_data = pd.read_csv(\"../Curated_data/cluster_0_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mineral = 'Density_gcm3'\n",
    "filter = ['Sulph1_Code', 'Sulph1_Pct', 'Sulph2_Code', 'Sulph2_Pct']\n",
    "deposit_data = density_data\n",
    "\n",
    "deposit_data = deposit_data.dropna(subset=[mineral] + filter)\n",
    "df1 = deposit_data\n",
    "variable=mineral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_composite_1covariates = deposit_data\n",
    "\n",
    "# Calculate the percentage of missing values for each variable\n",
    "missing_percentage = (two_composite_1covariates.isnull().sum() / len(two_composite_1covariates)) * 100\n",
    "\n",
    "# Identify variables with more than 15% missing values\n",
    "variables_to_remove = missing_percentage[missing_percentage > 5].index\n",
    "\n",
    "# Drop the identified variables from the DataFrame\n",
    "two_composite_1covariates = two_composite_1covariates.drop(columns=variables_to_remove)\n",
    "\n",
    "\n",
    "encoded_data = two_composite_1covariates.copy()\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "for column in two_composite_1covariates.columns:\n",
    "    if two_composite_1covariates[column].dtype == 'object':\n",
    "        unique_values = two_composite_1covariates[column].nunique()\n",
    "        \n",
    "        # Check if the number of unique values is within the threshold\n",
    "        if unique_values <= threshold:\n",
    "            # Perform one-hot encoding for columns with unique values within the threshold\n",
    "            encoded_columns = pd.get_dummies(encoded_data[column], prefix=column)\n",
    "            encoded_columns = encoded_columns.astype(int)  # Convert to integers (0 or 1)\n",
    "            encoded_data = pd.concat([encoded_data, encoded_columns], axis=1)\n",
    "            encoded_data = encoded_data.drop(columns=[column])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identify the encoded columns based on the common pattern\n",
    "encoded_columns = [col for col in encoded_data.columns if '_Code_' in col]\n",
    "\n",
    "# List to store the total columns\n",
    "total_columns = []\n",
    "\n",
    "# Iterate through the encoded columns and calculate the total for each category\n",
    "for col in encoded_columns:\n",
    "    # Extract the prefix and original column name\n",
    "    prefix, original_column = col.split('_Code_')\n",
    "    \n",
    "    # Calculate the total for the category\n",
    "    total_column = f\"{original_column}_Total\"\n",
    "    total_columns.append(total_column)\n",
    "    \n",
    "    # Multiply the code column by the corresponding percentage column and sum them\n",
    "    encoded_data[total_column] = (\n",
    "        encoded_data[f\"{prefix}_Code_{original_column}\"] * encoded_data[f\"{prefix}_Pct\"]\n",
    "    )\n",
    "\n",
    "# List to store the total columns\n",
    "total_columns = []\n",
    "\n",
    "# Initialize a dictionary to accumulate totals for each category\n",
    "category_totals = {}\n",
    "\n",
    "# Iterate through the encoded columns and calculate the total for each category\n",
    "for col in encoded_columns:\n",
    "    # Extract the prefix and original column name\n",
    "    prefix, original_column = col.split('_Code_')\n",
    "    \n",
    "    # Calculate the total for the category\n",
    "    total_column = f\"{original_column}_Total\"\n",
    "    if total_column not in total_columns:\n",
    "        total_columns.append(total_column)\n",
    "    \n",
    "    # Multiply the code column by the corresponding percentage column\n",
    "    total_values = encoded_data[f\"{prefix}_Code_{original_column}\"] * encoded_data[f\"{prefix}_Pct\"]\n",
    "    \n",
    "    # Accumulate the totals for each category\n",
    "    if total_column in category_totals:\n",
    "        category_totals[total_column] += total_values\n",
    "    else:\n",
    "        category_totals[total_column] = total_values\n",
    "\n",
    "# Add accumulated totals to the DataFrame\n",
    "for total_column, total_values in category_totals.items():\n",
    "    encoded_data[total_column] = total_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = ['Sc_ppm',\n",
    " 'Al_pct',\n",
    " 'Y_ppm',\n",
    " 'V_ppm',\n",
    " 'Sr_ppm',\n",
    " 'Ca_pct',\n",
    " 'P_ppm',\n",
    " 'Si_pct',\n",
    " 'Li_ppm',\n",
    " 'Mg_pct',\n",
    " 'La_ppm',\n",
    " 'RQD_Pct',\n",
    " 'Alt1_Int_wk',\n",
    " 'Ba_ppm',\n",
    " 'Sulph1_Code_PO',\n",
    " 'IP_pct',\n",
    " 'Sulph2_Code_CP',\n",
    " 'Sulph2_Code_PO',\n",
    " 'X',\n",
    " 'PY_Total',\n",
    " 'Z',\n",
    " 'PO_Total',\n",
    " 'CP_Total',\n",
    " 'Cr_ppm',\n",
    " 'B_ppm',\n",
    " 'Y',\n",
    " 'Sb_ppm',\n",
    " 'Weathering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\443229254.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density_gcm3</th>\n",
       "      <th>RQD_Pct</th>\n",
       "      <th>Cr_ppm</th>\n",
       "      <th>CP_Total</th>\n",
       "      <th>PO_Total</th>\n",
       "      <th>PY_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498922.13</td>\n",
       "      <td>7511747.51</td>\n",
       "      <td>148.80</td>\n",
       "      <td>3.13</td>\n",
       "      <td>88.00</td>\n",
       "      <td>212.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498922.68</td>\n",
       "      <td>7511747.45</td>\n",
       "      <td>146.88</td>\n",
       "      <td>3.15</td>\n",
       "      <td>88.00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498945.16</td>\n",
       "      <td>7511745.25</td>\n",
       "      <td>70.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498945.73</td>\n",
       "      <td>7511745.20</td>\n",
       "      <td>68.22</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498946.29</td>\n",
       "      <td>7511745.15</td>\n",
       "      <td>66.30</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81071</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.52</td>\n",
       "      <td>7510618.17</td>\n",
       "      <td>85.03</td>\n",
       "      <td>3.44</td>\n",
       "      <td>92.35</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81072</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.32</td>\n",
       "      <td>7510617.19</td>\n",
       "      <td>83.30</td>\n",
       "      <td>3.43</td>\n",
       "      <td>92.35</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81073</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.13</td>\n",
       "      <td>7510616.22</td>\n",
       "      <td>81.56</td>\n",
       "      <td>3.44</td>\n",
       "      <td>85.84</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81074</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499346.93</td>\n",
       "      <td>7510615.24</td>\n",
       "      <td>79.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>85.84</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81075</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499346.74</td>\n",
       "      <td>7510614.27</td>\n",
       "      <td>78.09</td>\n",
       "      <td>3.41</td>\n",
       "      <td>85.84</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name           X           Y       Z  Density_gcm3  RQD_Pct  \\\n",
       "393    KV-NME001  3498922.13  7511747.51  148.80          3.13    88.00   \n",
       "394    KV-NME001  3498922.68  7511747.45  146.88          3.15    88.00   \n",
       "434    KV-NME001  3498945.16  7511745.25   70.14          3.22    99.00   \n",
       "435    KV-NME001  3498945.73  7511745.20   68.22          3.22    99.00   \n",
       "436    KV-NME001  3498946.29  7511745.15   66.30          3.22    99.00   \n",
       "...          ...         ...         ...     ...           ...      ...   \n",
       "81071      KV365  3499347.52  7510618.17   85.03          3.44    92.35   \n",
       "81072      KV365  3499347.32  7510617.19   83.30          3.43    92.35   \n",
       "81073      KV365  3499347.13  7510616.22   81.56          3.44    85.84   \n",
       "81074      KV365  3499346.93  7510615.24   79.83          3.40    85.84   \n",
       "81075      KV365  3499346.74  7510614.27   78.09          3.41    85.84   \n",
       "\n",
       "       Cr_ppm  CP_Total  PO_Total  PY_Total  \n",
       "393     212.6       1.0       1.0       0.0  \n",
       "394     268.0       1.0       1.0       0.0  \n",
       "434     215.0       1.0       1.0       0.0  \n",
       "435     236.0       1.5       2.0       0.0  \n",
       "436     256.0       2.0       3.0       0.0  \n",
       "...       ...       ...       ...       ...  \n",
       "81071   131.0       0.2       3.0       0.0  \n",
       "81072   125.0       0.2       3.0       0.0  \n",
       "81073   128.0       0.2       3.0       0.0  \n",
       "81074   129.0       0.2       3.0       0.0  \n",
       "81075   130.0       0.2       3.0       0.0  \n",
       "\n",
       "[2618 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_encoded_data = encoded_data[encoded_data.columns.intersection(variable_names+ ['Density_gcm3', 'Name'])]\n",
    "\n",
    "deposit_data = encoded_data[['Name', 'X', 'Y', 'Z', 'Density_gcm3', 'RQD_Pct', 'Cr_ppm', 'CP_Total',\n",
    "       'PO_Total', 'PY_Total']]\n",
    "total_columns = ['CP_Total','PO_Total', 'PY_Total']\n",
    "\n",
    "#all covariates\n",
    "#covariates = total_columns[:3] + ['RQD_Pct', 'Cr_ppm']\n",
    "#sulphides only\n",
    "#covariates = total_columns[:3] \n",
    "#No covariates, only spatial\n",
    "covariates = []\n",
    "\n",
    "deposit_data.describe()\n",
    "deposit_data.fillna(0, inplace=True)\n",
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density_gcm3</th>\n",
       "      <th>RQD_Pct</th>\n",
       "      <th>Cr_ppm</th>\n",
       "      <th>CP_Total</th>\n",
       "      <th>PO_Total</th>\n",
       "      <th>PY_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498922.13</td>\n",
       "      <td>7511747.51</td>\n",
       "      <td>148.80</td>\n",
       "      <td>3.13</td>\n",
       "      <td>88.00</td>\n",
       "      <td>212.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498922.68</td>\n",
       "      <td>7511747.45</td>\n",
       "      <td>146.88</td>\n",
       "      <td>3.15</td>\n",
       "      <td>88.00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498945.16</td>\n",
       "      <td>7511745.25</td>\n",
       "      <td>70.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498945.73</td>\n",
       "      <td>7511745.20</td>\n",
       "      <td>68.22</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>3498946.29</td>\n",
       "      <td>7511745.15</td>\n",
       "      <td>66.30</td>\n",
       "      <td>3.22</td>\n",
       "      <td>99.00</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81071</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.52</td>\n",
       "      <td>7510618.17</td>\n",
       "      <td>85.03</td>\n",
       "      <td>3.44</td>\n",
       "      <td>92.35</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81072</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.32</td>\n",
       "      <td>7510617.19</td>\n",
       "      <td>83.30</td>\n",
       "      <td>3.43</td>\n",
       "      <td>92.35</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81073</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499347.13</td>\n",
       "      <td>7510616.22</td>\n",
       "      <td>81.56</td>\n",
       "      <td>3.44</td>\n",
       "      <td>85.84</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81074</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499346.93</td>\n",
       "      <td>7510615.24</td>\n",
       "      <td>79.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>85.84</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81075</th>\n",
       "      <td>KV365</td>\n",
       "      <td>3499346.74</td>\n",
       "      <td>7510614.27</td>\n",
       "      <td>78.09</td>\n",
       "      <td>3.41</td>\n",
       "      <td>85.84</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name           X           Y       Z  Density_gcm3  RQD_Pct  \\\n",
       "393    KV-NME001  3498922.13  7511747.51  148.80          3.13    88.00   \n",
       "394    KV-NME001  3498922.68  7511747.45  146.88          3.15    88.00   \n",
       "434    KV-NME001  3498945.16  7511745.25   70.14          3.22    99.00   \n",
       "435    KV-NME001  3498945.73  7511745.20   68.22          3.22    99.00   \n",
       "436    KV-NME001  3498946.29  7511745.15   66.30          3.22    99.00   \n",
       "...          ...         ...         ...     ...           ...      ...   \n",
       "81071      KV365  3499347.52  7510618.17   85.03          3.44    92.35   \n",
       "81072      KV365  3499347.32  7510617.19   83.30          3.43    92.35   \n",
       "81073      KV365  3499347.13  7510616.22   81.56          3.44    85.84   \n",
       "81074      KV365  3499346.93  7510615.24   79.83          3.40    85.84   \n",
       "81075      KV365  3499346.74  7510614.27   78.09          3.41    85.84   \n",
       "\n",
       "       Cr_ppm  CP_Total  PO_Total  PY_Total  \n",
       "393     212.6       1.0       1.0       0.0  \n",
       "394     268.0       1.0       1.0       0.0  \n",
       "434     215.0       1.0       1.0       0.0  \n",
       "435     236.0       1.5       2.0       0.0  \n",
       "436     256.0       2.0       3.0       0.0  \n",
       "...       ...       ...       ...       ...  \n",
       "81071   131.0       0.2       3.0       0.0  \n",
       "81072   125.0       0.2       3.0       0.0  \n",
       "81073   128.0       0.2       3.0       0.0  \n",
       "81074   129.0       0.2       3.0       0.0  \n",
       "81075   130.0       0.2       3.0       0.0  \n",
       "\n",
       "[2618 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\1488387108.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\1488387108.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\1488387108.py:18: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to normalize\n",
    "columns_to_normalize = ['X', 'Y', 'Z']   # Add all columns you want to normalize\n",
    "\n",
    "min_values = deposit_data[columns_to_normalize].min()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = deposit_data[column] - min_values[column]\n",
    "\n",
    "# Calculate the minimum and maximum values from the entire dataset\n",
    "min_values = deposit_data[columns_to_normalize].min().min()\n",
    "max_values = deposit_data[columns_to_normalize].max().max()\n",
    "\n",
    "# Scale the data to (0, 1) using the calculated minimum and maximum values\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = (deposit_data[column] - min_values) / (max_values - min_values)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "deposit_data.loc[:, [mineral] +covariates] = scaler.fit_transform(deposit_data.loc[:,[mineral] + covariates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lon = df1.values[:,4]\n",
    "# lat = df1.values[:,5]\n",
    "# az = df1.values[:,6]\n",
    "\n",
    "# normalized_lon = (lon-min(lon))/(max(lon)-min(lon))\n",
    "# normalized_lat = (lat-min(lat))/(max(lat)-min(lat))\n",
    "# normalized_az = (az-min(az))/(max(az)-min(az))\n",
    "# N = lon.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Lon: [0.43781378776682156 0.43806121898106964 0.4481744075146454 ...\n",
      " 0.6290106350432114 0.6289206600563835 0.6288351838188028]\n",
      "Normalized Lat: [0.5098162710765618 0.5097892785806601 0.5087995537240868 ...\n",
      " 0.0008772561228813492 0.0004363786870266015 0.0]\n",
      "Normalized Az: [0.46145471558890383 0.4605909557141493 0.42606755322005485 ...\n",
      " 0.4312051249751051 0.43042684133795656 0.4296440589514603]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lon = df1.values[:, 4]\n",
    "lat = df1.values[:, 5]\n",
    "az = df1.values[:, 6]\n",
    "\n",
    "# Subtract the minimum values for each array\n",
    "lon = lon - np.min(lon)\n",
    "lat = lat - np.min(lat)\n",
    "az = az - np.min(az)\n",
    "\n",
    "# Calculate the overall minimum and maximum values from the entire dataset\n",
    "min_value = np.min([np.min(lon), np.min(lat), np.min(az)])\n",
    "max_value = np.max([np.max(lon), np.max(lat), np.max(az)])\n",
    "\n",
    "# Scale the arrays to (0, 1) using the calculated minimum and maximum values\n",
    "normalized_lon = (lon - min_value) / (max_value - min_value)\n",
    "normalized_lat = (lat - min_value) / (max_value - min_value)\n",
    "normalized_az = (az - min_value) / (max_value - min_value)\n",
    "\n",
    "N = lon.shape[0]\n",
    "\n",
    "# Display the normalized arrays\n",
    "print(\"Normalized Lon:\", normalized_lon)\n",
    "print(\"Normalized Lat:\", normalized_lat)\n",
    "print(\"Normalized Az:\", normalized_az)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_basis = [10**3,19**3,37**3]\n",
    "knots_1dx = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dy = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dz = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "\n",
    "\n",
    "##Wendland kernel\n",
    "basis_size = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/(num_basis[res]**(1/3))*2.5\n",
    "    knots_x, knots_y, knots_z = np.meshgrid(knots_1dx[res],knots_1dy[res], knots_1dz[res])\n",
    "    knots = np.column_stack((knots_x.flatten(),knots_y.flatten(),knots_z.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(np.vstack((normalized_lon,normalized_lat, normalized_az)).astype(float).T-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + basis_size] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + basis_size] = 0\n",
    "    basis_size = basis_size + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2618, 58512)\n",
      "(2618, 6403)\n"
     ]
    }
   ],
   "source": [
    "## Romove the all-zero columns\n",
    "idx_zero = np.array([], dtype=int)\n",
    "for i in range(phi.shape[1]):\n",
    "    if sum(phi[:,i]!=0)==0:\n",
    "        idx_zero = np.append(idx_zero,int(i))\n",
    "\n",
    "phi_reduce = np.delete(phi,idx_zero,1)\n",
    "print(phi.shape)\n",
    "print(phi_reduce.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      phi_0  phi_1  phi_2  phi_3  phi_4  phi_5  phi_6     phi_7     phi_8  \\\n",
      "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000   \n",
      "...     ...    ...    ...    ...    ...    ...    ...       ...       ...   \n",
      "2613    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000246  0.003618   \n",
      "2614    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000262  0.003631   \n",
      "2615    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000279  0.003641   \n",
      "2616    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000297  0.003651   \n",
      "2617    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000315  0.003659   \n",
      "\n",
      "         phi_9  ...  phi_6393  phi_6394  phi_6395  phi_6396  phi_6397  \\\n",
      "0     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "1     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "3     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "4     0.000000  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "2613  0.000032  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2614  0.000029  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2615  0.000027  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2616  0.000025  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "2617  0.000023  ...       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "      phi_6398  phi_6399  phi_6400  phi_6401  phi_6402  \n",
      "0          0.0       0.0       0.0       0.0       0.0  \n",
      "1          0.0       0.0       0.0       0.0       0.0  \n",
      "2          0.0       0.0       0.0       0.0       0.0  \n",
      "3          0.0       0.0       0.0       0.0       0.0  \n",
      "4          0.0       0.0       0.0       0.0       0.0  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "2613       0.0       0.0       0.0       0.0       0.0  \n",
      "2614       0.0       0.0       0.0       0.0       0.0  \n",
      "2615       0.0       0.0       0.0       0.0       0.0  \n",
      "2616       0.0       0.0       0.0       0.0       0.0  \n",
      "2617       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[2618 rows x 6403 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_phi = np.shape(phi_reduce)[1]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(phi_reduce, columns=[f'phi_{i}' for i in range(len_phi)])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density_gcm3</th>\n",
       "      <th>RQD_Pct</th>\n",
       "      <th>Cr_ppm</th>\n",
       "      <th>CP_Total</th>\n",
       "      <th>PO_Total</th>\n",
       "      <th>PY_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>phi_6393</th>\n",
       "      <th>phi_6394</th>\n",
       "      <th>phi_6395</th>\n",
       "      <th>phi_6396</th>\n",
       "      <th>phi_6397</th>\n",
       "      <th>phi_6398</th>\n",
       "      <th>phi_6399</th>\n",
       "      <th>phi_6400</th>\n",
       "      <th>phi_6401</th>\n",
       "      <th>phi_6402</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.437814</td>\n",
       "      <td>0.509816</td>\n",
       "      <td>0.461455</td>\n",
       "      <td>0.400922</td>\n",
       "      <td>88.00</td>\n",
       "      <td>212.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.438061</td>\n",
       "      <td>0.509789</td>\n",
       "      <td>0.460591</td>\n",
       "      <td>0.410138</td>\n",
       "      <td>88.00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448174</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.426068</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>99.00</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448431</td>\n",
       "      <td>0.508777</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>99.00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448683</td>\n",
       "      <td>0.508755</td>\n",
       "      <td>0.424340</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>99.00</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629186</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.432766</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>92.35</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629096</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.431988</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>92.35</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629011</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>85.84</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.628921</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.430427</td>\n",
       "      <td>0.525346</td>\n",
       "      <td>85.84</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.628835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429644</td>\n",
       "      <td>0.529954</td>\n",
       "      <td>85.84</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows × 6413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name         X         Y         Z  Density_gcm3  RQD_Pct  Cr_ppm  \\\n",
       "0     KV-NME001  0.437814  0.509816  0.461455      0.400922    88.00   212.6   \n",
       "1     KV-NME001  0.438061  0.509789  0.460591      0.410138    88.00   268.0   \n",
       "2     KV-NME001  0.448174  0.508800  0.426068      0.442396    99.00   215.0   \n",
       "3     KV-NME001  0.448431  0.508777  0.425204      0.442396    99.00   236.0   \n",
       "4     KV-NME001  0.448683  0.508755  0.424340      0.442396    99.00   256.0   \n",
       "...         ...       ...       ...       ...           ...      ...     ...   \n",
       "2613      KV365  0.629186  0.001755  0.432766      0.543779    92.35   131.0   \n",
       "2614      KV365  0.629096  0.001314  0.431988      0.539171    92.35   125.0   \n",
       "2615      KV365  0.629011  0.000877  0.431205      0.543779    85.84   128.0   \n",
       "2616      KV365  0.628921  0.000436  0.430427      0.525346    85.84   129.0   \n",
       "2617      KV365  0.628835  0.000000  0.429644      0.529954    85.84   130.0   \n",
       "\n",
       "      CP_Total  PO_Total  PY_Total  ...  phi_6393  phi_6394  phi_6395  \\\n",
       "0          1.0       1.0       0.0  ...       0.0       0.0       0.0   \n",
       "1          1.0       1.0       0.0  ...       0.0       0.0       0.0   \n",
       "2          1.0       1.0       0.0  ...       0.0       0.0       0.0   \n",
       "3          1.5       2.0       0.0  ...       0.0       0.0       0.0   \n",
       "4          2.0       3.0       0.0  ...       0.0       0.0       0.0   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2613       0.2       3.0       0.0  ...       0.0       0.0       0.0   \n",
       "2614       0.2       3.0       0.0  ...       0.0       0.0       0.0   \n",
       "2615       0.2       3.0       0.0  ...       0.0       0.0       0.0   \n",
       "2616       0.2       3.0       0.0  ...       0.0       0.0       0.0   \n",
       "2617       0.2       3.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "      phi_6396  phi_6397  phi_6398  phi_6399  phi_6400  phi_6401  phi_6402  \n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2613       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2614       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2615       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2616       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2617       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[2618 rows x 6413 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reset = df.reset_index(drop=True)\n",
    "deposit_data_reset = deposit_data.reset_index(drop=True)\n",
    "\n",
    "# Concatenate along columns\n",
    "deposit_data = pd.concat([deposit_data_reset, df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phi_0', 'phi_1', 'phi_2', 'phi_3', 'phi_4', 'phi_5', 'phi_6', 'phi_7', 'phi_8', 'phi_9']\n"
     ]
    }
   ],
   "source": [
    "# Assuming deposit_data is your DataFrame\n",
    "# Extract the names of the first 98 columns\n",
    "phi_columns = deposit_data.columns[10:].tolist()\n",
    "\n",
    "# Display the list of column names\n",
    "print(phi_columns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data = deposit_data.dropna(subset=['Density_gcm3'] + covariates + phi_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\146396046.py:27: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\146396046.py:28: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\146396046.py:29: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_12416\\146396046.py:30: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Iteration 0, MSE: 0.5211\n",
      "- Iteration 100, MSE: 0.0115\n",
      "- Iteration 200, MSE: 0.0050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23478671\\Github\\PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation\\Paper 3 PhD BNNs for multivariate predictions\\DeepKriging\\DeepKriging_3D.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/DeepKriging/DeepKriging_3D.ipynb#X21sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m test_losses \u001b[39m=\u001b[39m []   \u001b[39m# To store test losses during training\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/DeepKriging/DeepKriging_3D.ipynb#X21sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m601\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/DeepKriging/DeepKriging_3D.ipynb#X21sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     pre \u001b[39m=\u001b[39m model(x_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/DeepKriging/DeepKriging_3D.ipynb#X21sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     mse \u001b[39m=\u001b[39m mse_loss(pre, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/DeepKriging/DeepKriging_3D.ipynb#X21sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     cost \u001b[39m=\u001b[39m mse\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p = len(phi_columns) + len(covariates)\n",
    "\n",
    "x = deposit_data[phi_columns + covariates].values #[:,np.newaxis] makes the second dimension explicit\n",
    "y = deposit_data[[variable]].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "x = x.reshape(len(deposit_data),p)\n",
    "x = x[:,[i for i in range(p)]]\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "\n",
    "# Determine the size of the test set (e.g., 20% of the data)\n",
    "test_size = int(0.2 * len(x))\n",
    "\n",
    "# Generate random indices for the test set\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(in_features=p, out_features=1000),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(in_features=1000, out_features=1)\n",
    "# )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=p, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5) ,\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(in_features=100, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=100, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "#Apparently lr=0.005 is better than 0.01 and than 0.001: quicker and better convergence\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []  # To store training losses during training\n",
    "test_losses = []   # To store test losses during training\n",
    "\n",
    "for step in range(601):\n",
    "    pre = model(x_train)\n",
    "    mse = mse_loss(pre, y_train)\n",
    "    cost = mse\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pre_train = model(x_train)\n",
    "    mse_train = mse_loss(pre_train, y_train)\n",
    "    train_losses.append(mse_train.item())\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pre_test = model(x_test)\n",
    "    mse_test = mse_loss(pre_test, y_test)\n",
    "    test_losses.append(mse_test.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f'- Iteration {step}, MSE: {mse.item():.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "#plt.ylim(0, 0.5)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.5 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.04)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.2 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST DEEPKRIGING NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0032\n",
      "  RMSE: 0.0569\n",
      "  MAE: 0.0408\n",
      "  R^2: 0.7969\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0031\n",
      "  RMSE: 0.0560\n",
      "  MAE: 0.0398\n",
      "  R^2: 0.7611\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0042\n",
      "  RMSE: 0.0651\n",
      "  MAE: 0.0447\n",
      "  R^2: 0.7127\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0036\n",
      "  RMSE: 0.0596\n",
      "  MAE: 0.0452\n",
      "  R^2: 0.7369\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0038\n",
      "  RMSE: 0.0618\n",
      "  MAE: 0.0456\n",
      "  R^2: 0.7876\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0034\n",
      "  RMSE: 0.0584\n",
      "  MAE: 0.0414\n",
      "  R^2: 0.7322\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0031\n",
      "  RMSE: 0.0555\n",
      "  MAE: 0.0398\n",
      "  R^2: 0.8292\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0025\n",
      "  RMSE: 0.0504\n",
      "  MAE: 0.0388\n",
      "  R^2: 0.8592\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0034\n",
      "  RMSE: 0.0585\n",
      "  MAE: 0.0447\n",
      "  R^2: 0.7299\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0589\n",
      "  MAE: 0.0428\n",
      "  R^2: 0.8235\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0034\n",
      "  Average MAE: 0.0424\n",
      "  Average R2: 0.7769\n",
      "  STD MSE: 0.0004\n",
      "  STD MAE: 0.0024\n",
      "  STD R2: 0.0473\n"
     ]
    }
   ],
   "source": [
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # # Use ACD for interpretations\n",
    "    # from acd import AttributionPriorExplainer\n",
    "    # explainer = AttributionPriorExplainer(model, method='cd')\n",
    "    # feature_attributions = explainer.attributions(torch.tensor(x_test, dtype=torch.float32))\n",
    "\n",
    "    # # Print or analyze interpretations as needed\n",
    "    # print(f\"\\nFeature Attributions for Fold {fold + 1}:\")\n",
    "    # print(\"Feature Attributions:\")\n",
    "    # print(feature_attributions.numpy())\n",
    "\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS W the 2 covaraites, no suplhides\n",
    "\\\n",
    "Average Metrics Across Folds:\n",
    "\\\n",
    "  Average MSE: 0.0033 \n",
    "  \\\n",
    "  Average MAE: 0.0403 \n",
    "  \\\n",
    "  STD MAE: 0.0027\n",
    "  \\\n",
    "  STD MSE: 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS W THE 5 covariates, WITH sulphides:\n",
    "\\\n",
    "Average Metrics Across Folds:\n",
    "\\\n",
    "  Average MSE: 0.0031\n",
    "  \\\n",
    "  Average MAE: 0.0392\n",
    "  \\\n",
    "  STD MAE: 0.0028\n",
    "  \\\n",
    "  STD MSE: 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS W THE 5 covariates, WITH sulphides AND normalising to keep distances:\n",
    "\\\n",
    "Average Metrics Across Folds:\n",
    "\\\n",
    "  Average MSE: 0.0031\n",
    "  \\\n",
    "  Average MAE: 0.0392\n",
    "  \\\n",
    "  STD MAE: 0.0028\n",
    "  \\\n",
    "  STD MSE: 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0033\n",
      "  RMSE: 0.0578\n",
      "  MAE: 0.0442\n",
      "  R^2: 0.7905\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0040\n",
      "  RMSE: 0.0630\n",
      "  MAE: 0.0400\n",
      "  R^2: 0.6973\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0059\n",
      "  RMSE: 0.0771\n",
      "  MAE: 0.0454\n",
      "  R^2: 0.5969\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0595\n",
      "  MAE: 0.0401\n",
      "  R^2: 0.7378\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0032\n",
      "  RMSE: 0.0565\n",
      "  MAE: 0.0420\n",
      "  R^2: 0.8225\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0029\n",
      "  RMSE: 0.0537\n",
      "  MAE: 0.0373\n",
      "  R^2: 0.7731\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0046\n",
      "  RMSE: 0.0681\n",
      "  MAE: 0.0462\n",
      "  R^2: 0.7433\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0038\n",
      "  RMSE: 0.0615\n",
      "  MAE: 0.0424\n",
      "  R^2: 0.7899\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0032\n",
      "  RMSE: 0.0570\n",
      "  MAE: 0.0427\n",
      "  R^2: 0.7441\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0050\n",
      "  RMSE: 0.0706\n",
      "  MAE: 0.0455\n",
      "  R^2: 0.7469\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0040\n",
      "  Average MAE: 0.0426\n",
      "  Average R2: 0.7442\n",
      "  STD MSE: 0.0009\n",
      "  STD MAE: 0.0027\n",
      "  STD R2: 0.0593\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # Function to print evaluation metrics\n",
    "# def print_metrics(actual, predicted, set_name):\n",
    "#     mse = mean_squared_error(actual, predicted)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(actual, predicted)\n",
    "#     r2 = r2_score(actual, predicted)\n",
    "\n",
    "#     print(f\"Metrics for {set_name} set:\")\n",
    "#     print(f\"  MSE: {mse:.4f}\")\n",
    "#     print(f\"  RMSE: {rmse:.4f}\")\n",
    "#     print(f\"  MAE: {mae:.4f}\")\n",
    "#     print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# # Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# # Create an array to store metrics for each fold\n",
    "# test_mse_list = []\n",
    "# test_mae_list = []\n",
    "# test_r2_list = []\n",
    "\n",
    "# # Define the number of folds for cross-validation\n",
    "# num_folds = 10\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# # Define a neural network with separate branches for phi_columns and covariates\n",
    "# class GroupedNet(nn.Module):\n",
    "#     def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "#         super(GroupedNet, self).__init__()\n",
    "#         self.phi_branch = nn.Sequential(\n",
    "#             nn.Linear(in_features=input_size_phi, out_features=100),\n",
    "#             nn.Linear(in_features=100, out_features=1)\n",
    "     \n",
    "#         )\n",
    "#         self.covariates_branch = nn.Sequential(\n",
    "#             nn.Linear(in_features=input_size_covariates, out_features=100),\n",
    "#             nn.Linear(in_features=100, out_features=1)       \n",
    "#           )\n",
    "        \n",
    "#         self.combine_layer = nn.Sequential(\n",
    "#             nn.Linear(2, 100), \n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.BatchNorm1d(100),\n",
    "#             nn.Linear(in_features=100, out_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(in_features=100, out_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(100),\n",
    "#             nn.Linear(in_features=100, out_features=1)\n",
    "#         )\n",
    "                                           \n",
    "\n",
    "#     def forward(self, input_phi, input_covariates):\n",
    "#         phi_output = self.phi_branch(input_phi)\n",
    "#         covariates_output = self.covariates_branch(input_covariates)\n",
    "#         x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "#         output = self.combine_layer(x)\n",
    "#         return output\n",
    "\n",
    "# # Perform k-fold cross-validation\n",
    "# for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "#     train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "#     x_train_phi = train_data[phi_columns].values\n",
    "#     x_train_covariates = train_data[covariates].values\n",
    "#     y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "#     x_test_phi = test_data[phi_columns].values\n",
    "#     x_test_covariates = test_data[covariates].values\n",
    "#     y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "#     # Define your neural network\n",
    "#     model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "#     mse_loss = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#     train_losses = []  # To store training losses during training\n",
    "#     test_losses = []   # To store test losses during training\n",
    "\n",
    "#     # Training loop\n",
    "#     for step in range(601):\n",
    "#         pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "#         mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "#         cost = mse\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "#         mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "#         test_losses.append(mse_test.item())\n",
    "\n",
    "#     # Store metrics for this fold\n",
    "#     test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "#     test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "#     test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "#     test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "#     # Print metrics for the current fold\n",
    "#     print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "#     print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# # Print average\n",
    "# # Print average metrics across folds\n",
    "# print(\"\\nAverage Metrics Across Folds:\")\n",
    "# print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "# print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "# print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "# print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "# print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "# print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0595\n",
      "  MAE: 0.0386\n",
      "  R^2: 0.7782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0038\n",
      "  RMSE: 0.0614\n",
      "  MAE: 0.0421\n",
      "  R^2: 0.7122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0030\n",
      "  RMSE: 0.0550\n",
      "  MAE: 0.0380\n",
      "  R^2: 0.7948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0024\n",
      "  RMSE: 0.0494\n",
      "  MAE: 0.0377\n",
      "  R^2: 0.8191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0042\n",
      "  RMSE: 0.0651\n",
      "  MAE: 0.0456\n",
      "  R^2: 0.7641\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0036\n",
      "  RMSE: 0.0596\n",
      "  MAE: 0.0431\n",
      "  R^2: 0.7204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0036\n",
      "  RMSE: 0.0603\n",
      "  MAE: 0.0408\n",
      "  R^2: 0.7985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0590\n",
      "  MAE: 0.0421\n",
      "  R^2: 0.8068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0049\n",
      "  RMSE: 0.0702\n",
      "  MAE: 0.0462\n",
      "  R^2: 0.6107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning:\n",
      "\n",
      "Initializing zero-element tensors is a no-op\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0042\n",
      "  RMSE: 0.0647\n",
      "  MAE: 0.0459\n",
      "  R^2: 0.7870\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0037\n",
      "  Average MAE: 0.0420\n",
      "  Average R2: 0.7592\n",
      "  STD MSE: 0.0006\n",
      "  STD MAE: 0.0031\n",
      "  STD R2: 0.0596\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network with separate branches for phi_columns and covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "     \n",
    "        )\n",
    "        self.covariates_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_covariates, out_features=1)      \n",
    "          )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(2, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "                                           \n",
    "\n",
    "    def forward(self, input_phi, input_covariates):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        covariates_output = self.covariates_branch(input_covariates)\n",
    "        x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    x_train_covariates = train_data[covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    x_test_covariates = test_data[covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
