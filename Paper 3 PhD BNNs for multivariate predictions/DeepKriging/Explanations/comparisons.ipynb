{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy as sp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pykrige.ok import OrdinaryKriging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data = pd.read_csv(\"../../Curated_data/final_dataset.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns = ['CP_Total','PO_Total', 'PY_Total']\n",
    "\n",
    "#all covariates\n",
    "covariates = total_columns[:3] + ['RQD_Pct', 'Cr_ppm'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phi_6402'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming deposit_data is your DataFrame\n",
    "# Extract the names of the first 98 columns\n",
    "phi_columns = deposit_data.columns[10:].tolist()\n",
    "phi_columns[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name, num_predictors):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    n = len(actual)\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - num_predictors - 1))\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\")\n",
    "    print(f\"  Adjusted R^2: {adjusted_r2:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepkriging covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0024\n",
      "  RMSE: 0.0485\n",
      "  MAE: 0.0355\n",
      "  R^2: 0.8524\n",
      "  Adjusted R^2: 1.0063\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0031\n",
      "  RMSE: 0.0559\n",
      "  MAE: 0.0372\n",
      "  R^2: 0.7618\n",
      "  Adjusted R^2: 1.0101\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0029\n",
      "  RMSE: 0.0540\n",
      "  MAE: 0.0384\n",
      "  R^2: 0.8020\n",
      "  Adjusted R^2: 1.0084\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0018\n",
      "  RMSE: 0.0427\n",
      "  MAE: 0.0312\n",
      "  R^2: 0.8648\n",
      "  Adjusted R^2: 1.0057\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0030\n",
      "  RMSE: 0.0552\n",
      "  MAE: 0.0393\n",
      "  R^2: 0.8306\n",
      "  Adjusted R^2: 1.0072\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0525\n",
      "  MAE: 0.0367\n",
      "  R^2: 0.7834\n",
      "  Adjusted R^2: 1.0092\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0025\n",
      "  RMSE: 0.0505\n",
      "  MAE: 0.0383\n",
      "  R^2: 0.8590\n",
      "  Adjusted R^2: 1.0060\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0021\n",
      "  RMSE: 0.0456\n",
      "  MAE: 0.0338\n",
      "  R^2: 0.8844\n",
      "  Adjusted R^2: 1.0049\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0532\n",
      "  MAE: 0.0385\n",
      "  R^2: 0.7769\n",
      "  Adjusted R^2: 1.0094\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0025\n",
      "  RMSE: 0.0501\n",
      "  MAE: 0.0376\n",
      "  R^2: 0.8725\n",
      "  Adjusted R^2: 1.0054\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0026\n",
      "  Average MAE: 0.0366\n",
      "  Average Adjusted R2: 1.0073\n",
      "  STD MSE: 0.0004\n",
      "  STD MAE: 0.0024\n",
      "  STD Adjusted R2: 0.0018\n"
     ]
    }
   ],
   "source": [
    "phi_columns = deposit_data.columns[10:].tolist()\n",
    "p = len(covariates) +len(phi_columns)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "test_adjusted_r2_list = []\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "     # Calculate adjusted R-squared\n",
    "    n = len(y_test)\n",
    "    sst = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "    ssr = np.sum((test_predictions_fold - y_test) ** 2)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    test_adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "   # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\", p)\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average Adjusted R2: {np.mean(test_adjusted_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD Adjusted R2: {np.std(test_adjusted_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0067\n",
      "  RMSE: 0.0819\n",
      "  MAE: 0.0547\n",
      "  R^2: 0.5797\n",
      "  Adjusted R^2: 0.5664\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0074\n",
      "  RMSE: 0.0863\n",
      "  MAE: 0.0504\n",
      "  R^2: 0.4317\n",
      "  Adjusted R^2: 0.4137\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0059\n",
      "  RMSE: 0.0768\n",
      "  MAE: 0.0514\n",
      "  R^2: 0.5995\n",
      "  Adjusted R^2: 0.5868\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0070\n",
      "  RMSE: 0.0834\n",
      "  MAE: 0.0570\n",
      "  R^2: 0.4847\n",
      "  Adjusted R^2: 0.4684\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0061\n",
      "  RMSE: 0.0779\n",
      "  MAE: 0.0552\n",
      "  R^2: 0.6624\n",
      "  Adjusted R^2: 0.6517\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0060\n",
      "  RMSE: 0.0777\n",
      "  MAE: 0.0503\n",
      "  R^2: 0.5260\n",
      "  Adjusted R^2: 0.5110\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0076\n",
      "  RMSE: 0.0872\n",
      "  MAE: 0.0564\n",
      "  R^2: 0.5784\n",
      "  Adjusted R^2: 0.5651\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0083\n",
      "  RMSE: 0.0912\n",
      "  MAE: 0.0549\n",
      "  R^2: 0.5386\n",
      "  Adjusted R^2: 0.5241\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0051\n",
      "  RMSE: 0.0718\n",
      "  MAE: 0.0511\n",
      "  R^2: 0.5938\n",
      "  Adjusted R^2: 0.5809\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0056\n",
      "  RMSE: 0.0748\n",
      "  MAE: 0.0522\n",
      "  R^2: 0.7160\n",
      "  Adjusted R^2: 0.7070\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0066\n",
      "  Average MAE: 0.0534\n",
      "  Average Adjusted R2: 0.5575\n",
      "  STD MSE: 0.0009\n",
      "  STD MAE: 0.0024\n",
      "  STD Adjusted R2: 0.0804\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "p = len(covariates) + len(phi_columns)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "test_adjusted_r2_list = []\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "    \n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "        train_losses.append(mse.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "\n",
    "     # Calculate adjusted R-squared\n",
    "    n = len(y_test)\n",
    "    sst = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "    ssr = np.sum((test_predictions_fold - y_test) ** 2)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    test_adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "   # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\", p)\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average Adjusted R2: {np.mean(test_adjusted_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD Adjusted R2: {np.std(test_adjusted_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reg kriging covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.013648385980087299\n",
      "Mean Absolute Error (MAE): 0.07509199045290375\n",
      "Mean Adjusted R-squared: 0.10163260900323849\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "y = deposit_data['Density_gcm3'].values[:, np.newaxis]  # Keep variable as the output\n",
    "x = deposit_data[['X', 'Y', 'Z','CP_Total', 'PO_Total', 'PY_Total', 'RQD_Pct', 'Cr_ppm']].values\n",
    "x = x.reshape(len(deposit_data), 8)\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, mae_list, adjusted_r2_list = [], [], []\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_cv_train, X_cv_test = x[train_index], x[test_index]\n",
    "    y_cv_train, y_cv_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_cv_train, y_cv_train)\n",
    "\n",
    "    # Predictions from the regression model\n",
    "    y_cv_pred = regression_model.predict(X_cv_test)\n",
    "\n",
    "    # Residuals (the difference between actual and predicted values)\n",
    "    residuals = y_cv_test - y_cv_pred\n",
    "\n",
    "    # Ordinary Kriging on residuals\n",
    "    ok = OrdinaryKriging(X_cv_test[:, 0], X_cv_test[:, 1], residuals, variogram_model='linear', verbose=False)\n",
    "    kriging_pred, _ = ok.execute('grid', X_cv_test[:, 0], X_cv_test[:, 1])\n",
    "\n",
    "    # Use Kriging predictions directly\n",
    "    final_predictions = kriging_pred\n",
    "\n",
    "    # Combine regression predictions with kriging predictions\n",
    "    final_cv_predictions = y_cv_pred + kriging_pred\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    mse = np.mean((y_cv_test - final_cv_predictions) ** 2)\n",
    "    mae = np.mean(np.abs(y_cv_test - final_cv_predictions))\n",
    "    sst = np.mean((y_cv_test - np.mean(y_cv_test)) ** 2) * len(y_cv_test)\n",
    "    ssr = np.mean((final_cv_predictions - y_cv_test) ** 2) * len(y_cv_test)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "    \n",
    "    # Calculate adjusted R-squared\n",
    "    n = len(y_cv_test)\n",
    "    num_predictors = X_cv_test.shape[1]\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - num_predictors - 1))\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "# Calculate mean metrics across folds\n",
    "mean_mse = np.mean(mse_list)\n",
    "mean_mae = np.mean(mae_list)\n",
    "mean_adjusted_r2 = np.mean(adjusted_r2_list)\n",
    "\n",
    "# Print mean metrics\n",
    "print(f\"Mean Squared Error (MSE): {mean_mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_mae}\")\n",
    "print(f\"Mean Adjusted R-squared: {mean_adjusted_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepkriging no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0026\n",
      "  RMSE: 0.0511\n",
      "  MAE: 0.0373\n",
      "  R^2: 0.8365\n",
      "  Adjusted R^2: 1.0069\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0025\n",
      "  RMSE: 0.0496\n",
      "  MAE: 0.0347\n",
      "  R^2: 0.8120\n",
      "  Adjusted R^2: 1.0080\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0534\n",
      "  MAE: 0.0367\n",
      "  R^2: 0.8067\n",
      "  Adjusted R^2: 1.0082\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0025\n",
      "  RMSE: 0.0504\n",
      "  MAE: 0.0386\n",
      "  R^2: 0.8120\n",
      "  Adjusted R^2: 1.0080\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0529\n",
      "  MAE: 0.0394\n",
      "  R^2: 0.8445\n",
      "  Adjusted R^2: 1.0066\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0024\n",
      "  RMSE: 0.0485\n",
      "  MAE: 0.0375\n",
      "  R^2: 0.8151\n",
      "  Adjusted R^2: 1.0079\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0025\n",
      "  RMSE: 0.0502\n",
      "  MAE: 0.0369\n",
      "  R^2: 0.8603\n",
      "  Adjusted R^2: 1.0059\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0026\n",
      "  RMSE: 0.0510\n",
      "  MAE: 0.0388\n",
      "  R^2: 0.8558\n",
      "  Adjusted R^2: 1.0061\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0532\n",
      "  MAE: 0.0399\n",
      "  R^2: 0.7769\n",
      "  Adjusted R^2: 1.0094\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0593\n",
      "  MAE: 0.0430\n",
      "  R^2: 0.8215\n",
      "  Adjusted R^2: 1.0076\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0027\n",
      "  Average MAE: 0.0383\n",
      "  Average Adjusted R2: 1.0075\n",
      "  STD MSE: 0.0003\n",
      "  STD MAE: 0.0021\n",
      "  STD Adjusted R2: 0.0010\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_columns = deposit_data.columns[10:].tolist()\n",
    "p = len(phi_columns)\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "test_adjusted_r2_list = []\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "     # Calculate adjusted R-squared\n",
    "    n = len(y_test)\n",
    "    sst = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "    ssr = np.sum((test_predictions_fold - y_test) ** 2)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    test_adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "   # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\", p)\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average Adjusted R2: {np.mean(test_adjusted_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD Adjusted R2: {np.std(test_adjusted_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0065\n",
      "  RMSE: 0.0805\n",
      "  MAE: 0.0577\n",
      "  R^2: 0.5943\n",
      "  Adjusted R^2: 0.5896\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0109\n",
      "  RMSE: 0.1042\n",
      "  MAE: 0.0636\n",
      "  R^2: 0.1712\n",
      "  Adjusted R^2: 0.1616\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0047\n",
      "  RMSE: 0.0686\n",
      "  MAE: 0.0487\n",
      "  R^2: 0.6811\n",
      "  Adjusted R^2: 0.6774\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0056\n",
      "  RMSE: 0.0748\n",
      "  MAE: 0.0517\n",
      "  R^2: 0.5855\n",
      "  Adjusted R^2: 0.5807\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0123\n",
      "  RMSE: 0.1110\n",
      "  MAE: 0.0687\n",
      "  R^2: 0.3154\n",
      "  Adjusted R^2: 0.3074\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0084\n",
      "  RMSE: 0.0915\n",
      "  MAE: 0.0579\n",
      "  R^2: 0.3426\n",
      "  Adjusted R^2: 0.3350\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0050\n",
      "  RMSE: 0.0705\n",
      "  MAE: 0.0491\n",
      "  R^2: 0.7250\n",
      "  Adjusted R^2: 0.7218\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0112\n",
      "  RMSE: 0.1057\n",
      "  MAE: 0.0645\n",
      "  R^2: 0.3802\n",
      "  Adjusted R^2: 0.3730\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0051\n",
      "  RMSE: 0.0714\n",
      "  MAE: 0.0509\n",
      "  R^2: 0.5982\n",
      "  Adjusted R^2: 0.5935\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0082\n",
      "  RMSE: 0.0905\n",
      "  MAE: 0.0598\n",
      "  R^2: 0.5835\n",
      "  Adjusted R^2: 0.5786\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0078\n",
      "  Average MAE: 0.0573\n",
      "  Average Adjusted R2: 0.4918\n",
      "  STD MSE: 0.0027\n",
      "  STD MAE: 0.0067\n",
      "  STD Adjusted R2: 0.1745\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "p =  len(phi_columns)\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "test_adjusted_r2_list = []\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "     # Calculate adjusted R-squared\n",
    "    n = len(y_test)\n",
    "    sst = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "    ssr = np.sum((test_predictions_fold - y_test) ** 2)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "    test_adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "   # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\", p)\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average Adjusted R2: {np.mean(test_adjusted_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD Adjusted R2: {np.std(test_adjusted_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression kriging no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.014367284060944865\n",
      "Mean Absolute Error (MAE): 0.07749732186146643\n",
      "Mean Adjusted R-squared (R2): 0.336608309189098\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "y = deposit_data['Density_gcm3'].values[:, np.newaxis]  # Keep variable as the output\n",
    "x = deposit_data[['X', 'Y', 'Z']].values\n",
    "x = x.reshape(len(deposit_data), 3)\n",
    "\n",
    "mse_list = []\n",
    "mae_list = []\n",
    "test_adjusted_r2_list = []\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, mae_list, r2_list = [], [], []\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_cv_train, X_cv_test = x[train_index], x[test_index]\n",
    "    y_cv_train, y_cv_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Ordinary Kriging on residuals\n",
    "    ok = OrdinaryKriging(X_cv_test[:, 0], X_cv_test[:, 1], y_cv_test, variogram_model='linear', verbose=False)\n",
    "    kriging_pred, _ = ok.execute('grid', X_cv_test[:, 0], X_cv_test[:, 1])\n",
    "\n",
    "    final_cv_predictions =  kriging_pred\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    mse = np.mean((y_cv_test - final_cv_predictions) ** 2)\n",
    "    mae = np.mean(np.abs(y_cv_test - final_cv_predictions))\n",
    "    sst = np.mean((y_cv_test - np.mean(y_cv_test)) ** 2)*len(y_cv_test)\n",
    "    ssr = np.mean((final_cv_predictions - y_cv_test) ** 2)*len(y_cv_test)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "# Calculate mean metrics across folds\n",
    "mean_mse = np.mean(mse_list)\n",
    "mean_mae = np.mean(mae_list)\n",
    "mean_r2 = np.mean(r2_list)\n",
    "\n",
    "n = len(y_test)\n",
    "sst = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "ssr = np.sum((test_predictions_fold - y_test) ** 2)\n",
    "r2 = 1 - (ssr / sst)\n",
    "adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "test_adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "mean_a_r2 = np.mean(test_adjusted_r2_list)\n",
    "\n",
    "# Print mean metrics\n",
    "print(f\"Mean Squared Error (MSE): {mean_mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_mae}\")\n",
    "print(f\"Mean Adjusted R-squared (R2): {mean_a_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
