{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy as sp\n",
    "import scipy.cluster\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data = pd.read_csv(\"../../Curated_data/final_dataset.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns = ['CP_Total','PO_Total', 'PY_Total']\n",
    "\n",
    "#all covariates\n",
    "covariates = total_columns[:3] + ['RQD_Pct', 'Cr_ppm', 'Random_Values'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_6401\n"
     ]
    }
   ],
   "source": [
    "# Assuming deposit_data is your DataFrame\n",
    "# Extract the names of the first 98 columns\n",
    "phi_columns = deposit_data.columns[10:-1].tolist()\n",
    "\n",
    "# Display the list of column names\n",
    "print(phi_columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data['Random_Values'] = np.random.rand(len(deposit_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepkriging covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0033\n",
      "  RMSE: 0.0572\n",
      "  MAE: 0.0392\n",
      "  R^2: 0.7952\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0528\n",
      "  MAE: 0.0353\n",
      "  R^2: 0.7874\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0035\n",
      "  RMSE: 0.0595\n",
      "  MAE: 0.0393\n",
      "  R^2: 0.7599\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0026\n",
      "  RMSE: 0.0509\n",
      "  MAE: 0.0362\n",
      "  R^2: 0.8084\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0044\n",
      "  RMSE: 0.0666\n",
      "  MAE: 0.0437\n",
      "  R^2: 0.7537\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0525\n",
      "  MAE: 0.0364\n",
      "  R^2: 0.7837\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0027\n",
      "  RMSE: 0.0516\n",
      "  MAE: 0.0394\n",
      "  R^2: 0.8522\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0530\n",
      "  MAE: 0.0370\n",
      "  R^2: 0.8438\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0048\n",
      "  RMSE: 0.0695\n",
      "  MAE: 0.0468\n",
      "  R^2: 0.6194\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0038\n",
      "  RMSE: 0.0618\n",
      "  MAE: 0.0431\n",
      "  R^2: 0.8059\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0033\n",
      "  Average MAE: 0.0396\n",
      "  Average R2: 0.7810\n",
      "  STD MSE: 0.0007\n",
      "  STD MAE: 0.0036\n",
      "  STD R2: 0.0616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phi_columns = deposit_data.columns[10:-1].tolist()\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0122\n",
      "  RMSE: 0.1107\n",
      "  MAE: 0.0708\n",
      "  R^2: 0.2327\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0111\n",
      "  RMSE: 0.1052\n",
      "  MAE: 0.0660\n",
      "  R^2: 0.1565\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0125\n",
      "  RMSE: 0.1119\n",
      "  MAE: 0.0692\n",
      "  R^2: 0.1509\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0124\n",
      "  RMSE: 0.1113\n",
      "  MAE: 0.0710\n",
      "  R^2: 0.0819\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0155\n",
      "  RMSE: 0.1244\n",
      "  MAE: 0.0788\n",
      "  R^2: 0.1389\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0109\n",
      "  RMSE: 0.1045\n",
      "  MAE: 0.0697\n",
      "  R^2: 0.1414\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0161\n",
      "  RMSE: 0.1267\n",
      "  MAE: 0.0776\n",
      "  R^2: 0.1107\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0163\n",
      "  RMSE: 0.1278\n",
      "  MAE: 0.0785\n",
      "  R^2: 0.0935\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0112\n",
      "  RMSE: 0.1060\n",
      "  MAE: 0.0723\n",
      "  R^2: 0.1140\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0183\n",
      "  RMSE: 0.1354\n",
      "  MAE: 0.0881\n",
      "  R^2: 0.0682\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0137\n",
      "  Average MAE: 0.0742\n",
      "  Average R2: 0.1289\n",
      "  STD MSE: 0.0025\n",
      "  STD MAE: 0.0062\n",
      "  STD R2: 0.0447\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "p = len(covariates) + len(phi_columns)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CP_Total', 'PO_Total', 'PY_Total', 'RQD_Pct', 'Cr_ppm', 'Random_Values']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reg kriging covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.013664941227511046\n",
      "Mean Absolute Error (MAE): 0.07514578640239988\n",
      "Mean R-squared (R2): 0.12803822086217215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "y = deposit_data['Density_gcm3'].values[:, np.newaxis]  # Keep variable as the output\n",
    "x = deposit_data[['X', 'Y', 'Z','CP_Total', 'PO_Total', 'PY_Total', 'RQD_Pct', 'Cr_ppm', 'Random_Values']].values\n",
    "x = x.reshape(len(deposit_data), 9)\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, mae_list, r2_list = [], [], []\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_cv_train, X_cv_test = x[train_index], x[test_index]\n",
    "    y_cv_train, y_cv_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_cv_train, y_cv_train)\n",
    "\n",
    "    # Predictions from the regression model\n",
    "    y_cv_pred = regression_model.predict(X_cv_test)\n",
    "\n",
    "    # Residuals (the difference between actual and predicted values)\n",
    "    residuals = y_cv_test - y_cv_pred\n",
    "\n",
    "    # Ordinary Kriging on residuals\n",
    "    #ok = OrdinaryKriging(X_cv_test[:, 0], X_cv_test[:, 1], y_cv_test, variogram_model='linear', verbose=False)\n",
    "    # kriging_pred, _ = ok.execute('grid', X_cv_test[:, 0], X_cv_test[:, 1])\n",
    "    ok = OrdinaryKriging(X_cv_test[:, 0], X_cv_test[:, 1], residuals, variogram_model='linear', verbose=False)\n",
    "    kriging_pred, _ = ok.execute('grid', X_cv_test[:, 0], X_cv_test[:, 1])\n",
    "\n",
    "\n",
    "    # Use Kriging predictions directly\n",
    "    final_predictions = kriging_pred\n",
    "\n",
    "    # Combine regression predictions with kriging predictions\n",
    "    final_cv_predictions = y_cv_pred + kriging_pred\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    mse = np.mean((y_cv_test - final_cv_predictions) ** 2)\n",
    "    mae = np.mean(np.abs(y_cv_test - final_cv_predictions))\n",
    "    sst = np.mean((y_cv_test - np.mean(y_cv_test)) ** 2)*len(y_cv_test)\n",
    "    ssr = np.mean((final_cv_predictions - y_cv_test) ** 2)*len(y_cv_test)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "# Calculate mean metrics across folds\n",
    "mean_mse = np.mean(mse_list)\n",
    "mean_mae = np.mean(mae_list)\n",
    "mean_r2 = np.mean(r2_list)\n",
    "\n",
    "# Print mean metrics\n",
    "print(f\"Mean Squared Error (MSE): {mean_mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_mae}\")\n",
    "print(f\"Mean R-squared (R2): {mean_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepkriging no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0028\n",
      "  RMSE: 0.0528\n",
      "  MAE: 0.0379\n",
      "  R^2: 0.8256\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0062\n",
      "  RMSE: 0.0788\n",
      "  MAE: 0.0539\n",
      "  R^2: 0.5258\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0040\n",
      "  RMSE: 0.0634\n",
      "  MAE: 0.0424\n",
      "  R^2: 0.7270\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0031\n",
      "  RMSE: 0.0558\n",
      "  MAE: 0.0406\n",
      "  R^2: 0.7691\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0036\n",
      "  RMSE: 0.0602\n",
      "  MAE: 0.0448\n",
      "  R^2: 0.7987\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0030\n",
      "  RMSE: 0.0550\n",
      "  MAE: 0.0405\n",
      "  R^2: 0.7618\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0041\n",
      "  RMSE: 0.0643\n",
      "  MAE: 0.0470\n",
      "  R^2: 0.7708\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0045\n",
      "  RMSE: 0.0670\n",
      "  MAE: 0.0487\n",
      "  R^2: 0.7512\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0048\n",
      "  RMSE: 0.0692\n",
      "  MAE: 0.0472\n",
      "  R^2: 0.6220\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0033\n",
      "  RMSE: 0.0576\n",
      "  MAE: 0.0438\n",
      "  R^2: 0.8315\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0040\n",
      "  Average MAE: 0.0447\n",
      "  Average R2: 0.7383\n",
      "  STD MSE: 0.0010\n",
      "  STD MAE: 0.0045\n",
      "  STD R2: 0.0903\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "p = len(covariates) + len(phi_columns)\n",
    "phi_columns = deposit_data.columns[10:-1].tolist()\n",
    "\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, phi_columns, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network without covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "        )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(1, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_phi):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        x = phi_output\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network without covariates\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Fold 1:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0142\n",
      "  RMSE: 0.1191\n",
      "  MAE: 0.0762\n",
      "  R^2: 0.1108\n",
      "\n",
      "\n",
      "Metrics for Fold 2:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0134\n",
      "  RMSE: 0.1156\n",
      "  MAE: 0.0771\n",
      "  R^2: -0.0197\n",
      "\n",
      "\n",
      "Metrics for Fold 3:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0147\n",
      "  RMSE: 0.1211\n",
      "  MAE: 0.0784\n",
      "  R^2: 0.0049\n",
      "\n",
      "\n",
      "Metrics for Fold 4:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0131\n",
      "  RMSE: 0.1143\n",
      "  MAE: 0.0756\n",
      "  R^2: 0.0319\n",
      "\n",
      "\n",
      "Metrics for Fold 5:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0181\n",
      "  RMSE: 0.1344\n",
      "  MAE: 0.0844\n",
      "  R^2: -0.0050\n",
      "\n",
      "\n",
      "Metrics for Fold 6:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0124\n",
      "  RMSE: 0.1114\n",
      "  MAE: 0.0744\n",
      "  R^2: 0.0239\n",
      "\n",
      "\n",
      "Metrics for Fold 7:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0184\n",
      "  RMSE: 0.1358\n",
      "  MAE: 0.0853\n",
      "  R^2: -0.0210\n",
      "\n",
      "\n",
      "Metrics for Fold 8:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0180\n",
      "  RMSE: 0.1341\n",
      "  MAE: 0.0846\n",
      "  R^2: 0.0012\n",
      "\n",
      "\n",
      "Metrics for Fold 9:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0126\n",
      "  RMSE: 0.1124\n",
      "  MAE: 0.0733\n",
      "  R^2: 0.0039\n",
      "\n",
      "\n",
      "Metrics for Fold 10:\n",
      "Metrics for Test set:\n",
      "  MSE: 0.0177\n",
      "  RMSE: 0.1330\n",
      "  MAE: 0.0824\n",
      "  R^2: 0.1008\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Average MSE: 0.0153\n",
      "  Average MAE: 0.0792\n",
      "  Average R2: 0.0232\n",
      "  STD MSE: 0.0024\n",
      "  STD MAE: 0.0043\n",
      "  STD R2: 0.0442\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "p = len(covariates) + len(phi_columns)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, phi_columns, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network without covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "        )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(1, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_phi):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        x = phi_output\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network without covariates\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression kriging no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.22492727759675396\n",
      "Mean Absolute Error (MAE): 0.4598115759529028\n",
      "Mean R-squared (R2): -13.745761019578921\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "y = deposit_data['Density_gcm3'].values[:, np.newaxis]  # Keep variable as the output\n",
    "x = deposit_data[['X', 'Y', 'Z']].values\n",
    "x = x.reshape(len(deposit_data), 3)\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, mae_list, r2_list = [], [], []\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_cv_train, X_cv_test = x[train_index], x[test_index]\n",
    "    y_cv_train, y_cv_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_cv_train, y_cv_train)\n",
    "\n",
    "    # Predictions from the regression model\n",
    "    y_cv_pred = regression_model.predict(X_cv_test)\n",
    "\n",
    "    # Residuals (the difference between actual and predicted values)\n",
    "    residuals = y_cv_test - y_cv_pred\n",
    "\n",
    "    # Ordinary Kriging on residuals\n",
    "    ok = OrdinaryKriging(X_cv_test[:, 0], X_cv_test[:, 1], y_cv_test, variogram_model='linear', verbose=False)\n",
    "    kriging_pred, _ = ok.execute('grid', X_cv_test[:, 0], X_cv_test[:, 1])\n",
    "\n",
    "\n",
    "    # Use Kriging predictions directly\n",
    "    final_predictions = kriging_pred\n",
    "\n",
    "    # Combine regression predictions with kriging predictions\n",
    "    final_cv_predictions = y_cv_pred + kriging_pred\n",
    "    #final_cv_predictions =  kriging_pred\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    mse = np.mean((y_cv_test - final_cv_predictions) ** 2)\n",
    "    mae = np.mean(np.abs(y_cv_test - final_cv_predictions))\n",
    "    sst = np.mean((y_cv_test - np.mean(y_cv_test)) ** 2)*len(y_cv_test)\n",
    "    ssr = np.mean((final_cv_predictions - y_cv_test) ** 2)*len(y_cv_test)\n",
    "    r2 = 1 - (ssr / sst)\n",
    "\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "# Calculate mean metrics across folds\n",
    "mean_mse = np.mean(mse_list)\n",
    "mean_mae = np.mean(mae_list)\n",
    "mean_r2 = np.mean(r2_list)\n",
    "\n",
    "# Print mean metrics\n",
    "print(f\"Mean Squared Error (MSE): {mean_mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_mae}\")\n",
    "print(f\"Mean R-squared (R2): {mean_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
