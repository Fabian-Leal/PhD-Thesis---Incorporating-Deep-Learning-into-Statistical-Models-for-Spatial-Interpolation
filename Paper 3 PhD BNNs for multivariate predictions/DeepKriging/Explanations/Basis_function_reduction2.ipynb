{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy as sp\n",
    "import scipy.cluster\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = len(density_data)\n",
    "# d = 3\n",
    "# root = N**(1/d)\n",
    "# H = 1 + math.log10(root/10) / math.log10(2)\n",
    "# print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density_gcm3</th>\n",
       "      <th>RQD_Pct</th>\n",
       "      <th>Cr_ppm</th>\n",
       "      <th>CP_Total</th>\n",
       "      <th>PO_Total</th>\n",
       "      <th>PY_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>phi_6393</th>\n",
       "      <th>phi_6394</th>\n",
       "      <th>phi_6395</th>\n",
       "      <th>phi_6396</th>\n",
       "      <th>phi_6397</th>\n",
       "      <th>phi_6398</th>\n",
       "      <th>phi_6399</th>\n",
       "      <th>phi_6400</th>\n",
       "      <th>phi_6401</th>\n",
       "      <th>phi_6402</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.437814</td>\n",
       "      <td>0.509816</td>\n",
       "      <td>0.461455</td>\n",
       "      <td>0.400922</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.127305</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.438061</td>\n",
       "      <td>0.509789</td>\n",
       "      <td>0.460591</td>\n",
       "      <td>0.410138</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.160479</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448174</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.426068</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.128743</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448431</td>\n",
       "      <td>0.508777</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.141317</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KV-NME001</td>\n",
       "      <td>0.448683</td>\n",
       "      <td>0.508755</td>\n",
       "      <td>0.424340</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.153293</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629186</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.432766</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629096</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.431988</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.629011</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.076647</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.628921</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.430427</td>\n",
       "      <td>0.525346</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>KV365</td>\n",
       "      <td>0.628835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429644</td>\n",
       "      <td>0.529954</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.077844</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows Ã— 6413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name         X         Y         Z  Density_gcm3  RQD_Pct  \\\n",
       "0     KV-NME001  0.437814  0.509816  0.461455      0.400922   0.8800   \n",
       "1     KV-NME001  0.438061  0.509789  0.460591      0.410138   0.8800   \n",
       "2     KV-NME001  0.448174  0.508800  0.426068      0.442396   0.9900   \n",
       "3     KV-NME001  0.448431  0.508777  0.425204      0.442396   0.9900   \n",
       "4     KV-NME001  0.448683  0.508755  0.424340      0.442396   0.9900   \n",
       "...         ...       ...       ...       ...           ...      ...   \n",
       "2613      KV365  0.629186  0.001755  0.432766      0.543779   0.9235   \n",
       "2614      KV365  0.629096  0.001314  0.431988      0.539171   0.9235   \n",
       "2615      KV365  0.629011  0.000877  0.431205      0.543779   0.8584   \n",
       "2616      KV365  0.628921  0.000436  0.430427      0.525346   0.8584   \n",
       "2617      KV365  0.628835  0.000000  0.429644      0.529954   0.8584   \n",
       "\n",
       "        Cr_ppm  CP_Total  PO_Total  PY_Total  ...  phi_6393  phi_6394  \\\n",
       "0     0.127305     0.250  0.066667       0.0  ...       0.0       0.0   \n",
       "1     0.160479     0.250  0.066667       0.0  ...       0.0       0.0   \n",
       "2     0.128743     0.250  0.066667       0.0  ...       0.0       0.0   \n",
       "3     0.141317     0.375  0.133333       0.0  ...       0.0       0.0   \n",
       "4     0.153293     0.500  0.200000       0.0  ...       0.0       0.0   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "2613  0.078443     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2614  0.074850     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2615  0.076647     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2616  0.077246     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "2617  0.077844     0.050  0.200000       0.0  ...       0.0       0.0   \n",
       "\n",
       "      phi_6395  phi_6396  phi_6397  phi_6398  phi_6399  phi_6400  phi_6401  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2613       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2614       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2615       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2616       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2617       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      phi_6402  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "2613       0.0  \n",
       "2614       0.0  \n",
       "2615       0.0  \n",
       "2616       0.0  \n",
       "2617       0.0  \n",
       "\n",
       "[2618 rows x 6413 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_data = pd.read_csv(\"../../Curated_data/final_dataset_3_no_0.csv\", low_memory=False)\n",
    "density_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data = density_data.iloc[:, :10]\n",
    "X = deposit_data['X']\n",
    "Y = deposit_data['Y']\n",
    "Z = deposit_data['Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lon = deposit_data.values[:, 1]\n",
    "lat = deposit_data.values[:, 2]\n",
    "az = deposit_data.values[:, 3]\n",
    "\n",
    "# Subtract the minimum values for each array\n",
    "lon = lon - np.min(lon)\n",
    "lat = lat - np.min(lat)\n",
    "az = az - np.min(az)\n",
    "\n",
    "# Calculate the overall minimum and maximum values from the entire dataset\n",
    "min_value = np.min([np.min(lon), np.min(lat), np.min(az)])\n",
    "max_value = np.max([np.max(lon), np.max(lat), np.max(az)])\n",
    "\n",
    "# Scale the arrays to (0, 1) using the calculated minimum and maximum values\n",
    "normalized_lon = (lon - min_value) / (max_value - min_value)\n",
    "normalized_lat = (lat - min_value) / (max_value - min_value)\n",
    "normalized_az = (az - min_value) / (max_value - min_value)\n",
    "\n",
    "N = lon.shape[0]\n",
    "\n",
    "# Display the normalized arrays\n",
    "print(\"Normalized Lon:\", normalized_lon)\n",
    "print(\"Normalized Lat:\", normalized_lat)\n",
    "print(\"Normalized Az:\", normalized_az)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_basis = [10**3,19**3,37**3]\n",
    "knots_1dx = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dy = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dz = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "\n",
    "\n",
    "basis_size = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/(num_basis[res]**(1/3))*2.5\n",
    "    knots_x, knots_y, knots_z = np.meshgrid(knots_1dx[res],knots_1dy[res], knots_1dz[res])\n",
    "    knots = np.column_stack((knots_x.flatten(),knots_y.flatten(),knots_z.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(np.vstack((normalized_lon,normalized_lat, normalized_az)).astype(float).T-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + basis_size] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + basis_size] = 0\n",
    "    basis_size = basis_size + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_basis = [10**3]\n",
    "knots_1dx = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dy = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "knots_1dz = [np.linspace(0,1,int(i**(1/3))+1) for i in num_basis]\n",
    "\n",
    "\n",
    "\n",
    "basis_size = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "#For each level of resolution\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/(num_basis[res]**(1/3))*2.5\n",
    "    knots_x, knots_y, knots_z = np.meshgrid(knots_1dx[res],knots_1dy[res], knots_1dz[res])\n",
    "    knots = np.column_stack((knots_x.flatten(),knots_y.flatten(),knots_z.flatten()))\n",
    "    #For each node in the grid\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(np.vstack((normalized_lon,normalized_lat, normalized_az)).astype(float).T-knots[i,:],axis=1)/theta\n",
    "        # For each distance of our data to the node i, calculate Wendland kernel\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + basis_size] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + basis_size] = 0\n",
    "    basis_size = basis_size + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Romove the all-zero columns\n",
    "idx_zero = np.array([], dtype=int)\n",
    "for i in range(phi.shape[1]):\n",
    "    if sum(phi[:,i]!=0)==0:\n",
    "        idx_zero = np.append(idx_zero,int(i))\n",
    "\n",
    "phi_reduce = np.delete(phi,idx_zero,1)\n",
    "print(phi.shape)\n",
    "print(phi_reduce.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_reduce = phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len_phi = np.shape(phi_reduce)[1]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(phi_reduce, columns=[f'phi_{i}' for i in range(len_phi)])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset = df.reset_index(drop=True)\n",
    "deposit_data_reset = deposit_data.reset_index(drop=True)\n",
    "\n",
    "# Concatenate along columns\n",
    "deposit_data = pd.concat([deposit_data_reset, df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming deposit_data is your DataFrame\n",
    "# Extract the names of the first 98 columns\n",
    "phi_columns = deposit_data.columns[10:].tolist()\n",
    "\n",
    "# Display the list of column names\n",
    "print(phi_columns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns = ['CP_Total','PO_Total', 'PY_Total']\n",
    "\n",
    "#all covariates\n",
    "covariates = total_columns[:3] + ['RQD_Pct', 'Cr_ppm'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data = deposit_data.dropna(subset=['Density_gcm3'] + covariates + phi_columns)\n",
    "deposit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data.to_csv('final_dataset_1_delimited.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST DEEPKRIGING NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(phi_columns) + len(covariates)\n",
    "\n",
    "x = deposit_data[phi_columns + covariates].values #[:,np.newaxis] makes the second dimension explicit\n",
    "y = deposit_data[[variable]].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "x = x.reshape(len(deposit_data),p)\n",
    "x = x[:,[i for i in range(p)]]\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(phi_columns) + len(covariates)\n",
    "\n",
    "x = deposit_data[phi_columns + covariates].values #[:,np.newaxis] makes the second dimension explicit\n",
    "y = deposit_data[[variable]].values[:,np.newaxis] #[:,np.newaxis] makes the second dimension explicit\n",
    "x = x.reshape(len(deposit_data),p)\n",
    "x = x[:,[i for i in range(p)]]\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train = train_data[phi_columns + covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test = test_data[phi_columns + covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(in_features=p, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5) ,\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.Linear(in_features=100, out_features=1))\n",
    "\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data[phi_columns + covariates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # Function to print evaluation metrics\n",
    "# def print_metrics(actual, predicted, set_name):\n",
    "#     mse = mean_squared_error(actual, predicted)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(actual, predicted)\n",
    "#     r2 = r2_score(actual, predicted)\n",
    "\n",
    "#     print(f\"Metrics for {set_name} set:\")\n",
    "#     print(f\"  MSE: {mse:.4f}\")\n",
    "#     print(f\"  RMSE: {rmse:.4f}\")\n",
    "#     print(f\"  MAE: {mae:.4f}\")\n",
    "#     print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# # Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# # Create an array to store metrics for each fold\n",
    "# test_mse_list = []\n",
    "# test_mae_list = []\n",
    "# test_r2_list = []\n",
    "\n",
    "# # Define the number of folds for cross-validation\n",
    "# num_folds = 10\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# # Define a neural network with separate branches for phi_columns and covariates\n",
    "# class GroupedNet(nn.Module):\n",
    "#     def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "#         super(GroupedNet, self).__init__()\n",
    "#         self.phi_branch = nn.Sequential(\n",
    "#             nn.Linear(in_features=input_size_phi, out_features=100),\n",
    "#             nn.Linear(in_features=100, out_features=1)\n",
    "     \n",
    "#         )\n",
    "#         self.covariates_branch = nn.Sequential(\n",
    "#             nn.Linear(in_features=input_size_covariates, out_features=100),\n",
    "#             nn.Linear(in_features=100, out_features=1)       \n",
    "#           )\n",
    "        \n",
    "#         self.combine_layer = nn.Sequential(\n",
    "#             nn.Linear(2, 100), \n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.BatchNorm1d(100),\n",
    "#             nn.Linear(in_features=100, out_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(in_features=100, out_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(100),\n",
    "#             nn.Linear(in_features=100, out_features=1)\n",
    "#         )\n",
    "                                           \n",
    "\n",
    "#     def forward(self, input_phi, input_covariates):\n",
    "#         phi_output = self.phi_branch(input_phi)\n",
    "#         covariates_output = self.covariates_branch(input_covariates)\n",
    "#         x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "#         output = self.combine_layer(x)\n",
    "#         return output\n",
    "\n",
    "# # Perform k-fold cross-validation\n",
    "# for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "#     train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "#     x_train_phi = train_data[phi_columns].values\n",
    "#     x_train_covariates = train_data[covariates].values\n",
    "#     y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "#     x_test_phi = test_data[phi_columns].values\n",
    "#     x_test_covariates = test_data[covariates].values\n",
    "#     y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "#     # Define your neural network\n",
    "#     model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "#     mse_loss = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#     train_losses = []  # To store training losses during training\n",
    "#     test_losses = []   # To store test losses during training\n",
    "\n",
    "#     # Training loop\n",
    "#     for step in range(601):\n",
    "#         pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "#         mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "#         cost = mse\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "#         mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "#         test_losses.append(mse_test.item())\n",
    "\n",
    "#     # Store metrics for this fold\n",
    "#     test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "#     test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "#     test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "#     test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "#     # Print metrics for the current fold\n",
    "#     print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "#     print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# # Print average\n",
    "# # Print average metrics across folds\n",
    "# print(\"\\nAverage Metrics Across Folds:\")\n",
    "# print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "# print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "# print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "# print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "# print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "# print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST MODIFIED (Deepkriging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network with separate branches for phi_columns and covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "     \n",
    "        )\n",
    "        self.covariates_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_covariates, out_features=1)      \n",
    "          )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(2, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "                                           \n",
    "\n",
    "    def forward(self, input_phi, input_covariates):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        covariates_output = self.covariates_branch(input_covariates)\n",
    "        x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    x_train_covariates = train_data[covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    x_test_covariates = test_data[covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, covariates, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network with separate branches for phi_columns and covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, input_size_covariates, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "     \n",
    "        )\n",
    "        self.covariates_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_covariates, out_features=1)      \n",
    "          )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(2, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "                                           \n",
    "\n",
    "    def forward(self, input_phi, input_covariates):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        covariates_output = self.covariates_branch(input_covariates)\n",
    "        x = torch.cat((phi_output, covariates_output), dim=1)\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    x_train_covariates = train_data[covariates].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    x_test_covariates = test_data[covariates].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), input_size_covariates=len(covariates), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32), torch.tensor(x_train_covariates, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32), torch.tensor(x_test_covariates, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepkriging no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, phi_columns, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network without covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "        )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(1, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_phi):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        x = phi_output\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network without covariates\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_data[['X','Y','Z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN no covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "phi_columns = ['X','Y','Z']\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(actual, predicted, set_name):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(f\"Metrics for {set_name} set:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R^2: {r2:.4f}\\n\")\n",
    "\n",
    "# Assuming deposit_data, phi_columns, and other necessary variables are defined\n",
    "\n",
    "# Create an array to store metrics for each fold\n",
    "test_mse_list = []\n",
    "test_mae_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a neural network without covariates\n",
    "class GroupedNet(nn.Module):\n",
    "    def __init__(self, input_size_phi, output_size):\n",
    "        super(GroupedNet, self).__init__()\n",
    "        self.phi_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size_phi, out_features=1)\n",
    "        )\n",
    "        \n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(1, 100), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(in_features=100, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_phi):\n",
    "        phi_output = self.phi_branch(input_phi)\n",
    "        x = phi_output\n",
    "        output = self.combine_layer(x)\n",
    "        return output\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(deposit_data)):\n",
    "    train_data, test_data = deposit_data.iloc[train_index], deposit_data.iloc[test_index]\n",
    "\n",
    "    x_train_phi = train_data[phi_columns].values\n",
    "    y_train = train_data['Density_gcm3'].values\n",
    "\n",
    "    x_test_phi = test_data[phi_columns].values\n",
    "    y_test = test_data['Density_gcm3'].values\n",
    "\n",
    "    # Define your neural network without covariates\n",
    "    model = GroupedNet(input_size_phi=len(phi_columns), output_size=1)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []  # To store training losses during training\n",
    "    test_losses = []   # To store test losses during training\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(601):\n",
    "        pre = model(torch.tensor(x_train_phi, dtype=torch.float32))\n",
    "        mse = mse_loss(pre, torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32))\n",
    "        cost = mse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pre_test = model(torch.tensor(x_test_phi, dtype=torch.float32))\n",
    "        mse_test = mse_loss(pre_test, torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32))\n",
    "        test_losses.append(mse_test.item())\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    test_predictions_fold = model(torch.tensor(x_test_phi, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    test_mse_list.append(mean_squared_error(y_test, test_predictions_fold))\n",
    "    test_mae_list.append(mean_absolute_error(y_test, test_predictions_fold))\n",
    "    test_r2_list.append(r2_score(y_test, test_predictions_fold))\n",
    "\n",
    "    # Print metrics for the current fold\n",
    "    print(f\"\\nMetrics for Fold {fold + 1}:\")\n",
    "    print_metrics(y_test, test_predictions_fold, \"Test\")\n",
    "\n",
    "# Print average metrics across folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"  Average MSE: {np.mean(test_mse_list):.4f}\")\n",
    "print(f\"  Average MAE: {np.mean(test_mae_list):.4f}\")\n",
    "print(f\"  Average R2: {np.mean(test_r2_list):.4f}\")\n",
    "print(f\"  STD MSE: {np.std(test_mse_list):.4f}\")\n",
    "print(f\"  STD MAE: {np.std(test_mae_list):.4f}\")\n",
    "print(f\"  STD R2: {np.std(test_r2_list):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
