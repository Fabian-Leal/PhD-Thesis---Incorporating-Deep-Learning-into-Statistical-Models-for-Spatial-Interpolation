{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D prediction full deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_composite_filtered = pd.read_csv(\"Curated_data/two_composite_filtered.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_15680\\1641146031.py:26: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_15680\\1641146031.py:34: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_15680\\1641146031.py:42: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Iteration 0, MSE: 0.0049\n",
      "- Iteration 100, MSE: 0.0034\n",
      "- Iteration 200, MSE: 0.0032\n",
      "- Iteration 300, MSE: 0.0030\n",
      "- Iteration 400, MSE: 0.0029\n",
      "- Iteration 500, MSE: 0.0028\n",
      "- Iteration 600, MSE: 0.0028\n",
      "- Iteration 700, MSE: 0.0028\n",
      "- Iteration 800, MSE: 0.0028\n",
      "- Iteration 900, MSE: 0.0027\n",
      "- Iteration 1000, MSE: 0.0028\n",
      "- Iteration 1100, MSE: 0.0026\n",
      "- Iteration 1200, MSE: 0.0026\n",
      "- Iteration 1300, MSE: 0.0026\n",
      "- Iteration 1400, MSE: 0.0026\n",
      "- Iteration 1500, MSE: 0.0025\n",
      "- Iteration 1600, MSE: 0.0025\n",
      "- Iteration 1700, MSE: 0.0025\n",
      "- Iteration 1800, MSE: 0.0025\n",
      "- Iteration 1900, MSE: 0.0025\n",
      "- Iteration 2000, MSE: 0.0025\n",
      "- Iteration 2100, MSE: 0.0024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23478671\\Github\\PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation\\Paper 3 PhD BNNs for multivariate predictions\\NN 3D full deposit.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#X13sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m cost \u001b[39m=\u001b[39m mse\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#X13sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#X13sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m cost\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#X13sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#X13sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m pre_train \u001b[39m=\u001b[39m model(x_train)\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your data\n",
    "# deposit_data should contain your dataset with 'Name' representing holes and 'Density_gcm3' as the target variable\n",
    "# x and y should be defined as you did in your original code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mineral = 'Density_gcm3'\n",
    "two_composite_1mineral = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "deposit_data = two_composite_1mineral.dropna(subset=[mineral])\n",
    "    \n",
    "# Define the columns to normalize\n",
    "columns_to_normalize = ['X', 'Y', 'Z']  # Add all columns you want to normalize\n",
    "\n",
    "min_values = deposit_data[columns_to_normalize].min()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = deposit_data[column] - min_values[column]\n",
    "\n",
    "# Calculate the minimum and maximum values from the entire dataset\n",
    "min_values = deposit_data[columns_to_normalize].min().min()\n",
    "max_values = deposit_data[columns_to_normalize].max().max()\n",
    "\n",
    "# Scale the data to (0, 1) using the calculated minimum and maximum values\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = (deposit_data[column] - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler to your data and transform the specified columns\n",
    "deposit_data.loc[:, [mineral]] = scaler.fit_transform(deposit_data.loc[:, [mineral]])\n",
    "\n",
    "x = deposit_data[['X', 'Y', 'Z']].values  # Use X, Y, and Z coordinates\n",
    "y = deposit_data[mineral].values[:, np.newaxis]  # Keep mineral as the output\n",
    "x = x.reshape(len(deposit_data), 3)\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "# Determine the unique 'Name' values\n",
    "unique_names = deposit_data['Name'].unique()\n",
    "\n",
    "# Initialize empty lists to store training and testing data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Iterate through unique 'Name' values and assign each hole's data to either train or test\n",
    "for name in unique_names:\n",
    "    # Select data for the current hole\n",
    "    hole_data = deposit_data[deposit_data['Name'] == name]\n",
    "    x_hole = hole_data[['X', 'Y', 'Z']].values\n",
    "    y_hole = hole_data['Density_gcm3'].values\n",
    "\n",
    "    # Assign the hole's data to either train or test\n",
    "    if np.random.rand() < 0.2:  # You can adjust the ratio, e.g., 0.2 for a 80/20 split\n",
    "        x_test.extend(x_hole)\n",
    "        y_test.extend(y_hole)\n",
    "    else:\n",
    "        x_train.extend(x_hole)\n",
    "        y_train.extend(y_hole)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=3, out_features=500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=500, out_features=1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "#Apparently lr=0.005 is better than 0.01 and than 0.001: quicker and better convergence\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "train_losses = []  # To store training losses during training\n",
    "test_losses = []   # To store test losses during training\n",
    "\n",
    "for step in range(10001):\n",
    "    pre = model(x_train)\n",
    "    mse = mse_loss(pre, y_train)\n",
    "    cost = mse\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pre_train = model(x_train)\n",
    "    mse_train = mse_loss(pre_train, y_train)\n",
    "    train_losses.append(mse_train.item())\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pre_test = model(x_test)\n",
    "    mse_test = mse_loss(pre_test, y_test)\n",
    "    test_losses.append(mse_test.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f'- Iteration {step}, MSE: {mse.item():.4f}')\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "#plt.ylim(0, 0.5)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.5 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.05 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.004)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.025 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ... (previous code for data preprocessing)\n",
    "\n",
    "# Define a grid of points for prediction (including X, Y, and Z)\n",
    "x_grid = np.linspace(x[:, 0].min(), x[:, 0].max(), 50)\n",
    "y_grid = np.linspace(x[:, 1].min(), x[:, 1].max(), 50)\n",
    "z_grid = np.linspace(x[:, 2].min(), x[:, 2].max(), 50)\n",
    "xyz_grid = np.array(np.meshgrid(x_grid, y_grid, z_grid)).T.reshape(-1, 3)\n",
    "\n",
    "# Make predictions for the grid\n",
    "predictions = model(torch.tensor(xyz_grid, dtype=torch.float32))\n",
    "\n",
    "# Reshape the predictions to match the grid shape\n",
    "predictions = predictions.data.numpy().reshape(50, 50, 50)\n",
    "\n",
    "# Create a 3D surface plot using Plotly\n",
    "\n",
    "# Pool the values from predictions_hole and y_hole\n",
    "pooled_values = np.concatenate([predictions.ravel(), y_test.data.numpy()[:, 0]])\n",
    "\n",
    "# Determine the minimum and maximum values for the color mapping\n",
    "vmin = np.min(pooled_values)\n",
    "vmax = np.max(pooled_values)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "    x=xyz_grid[:,0],\n",
    "    y=xyz_grid[:,1],\n",
    "    z=xyz_grid[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=predictions.ravel(),\n",
    "        colorscale='viridis',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set',\n",
    "    text = [\"Density: {}\".format(x) for x in predictions.ravel() ]\n",
    "\n",
    ")])\n",
    "\n",
    "\n",
    "# Add a scatter plot for test data points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x_test.data.numpy()[:, 0],\n",
    "    y=x_test.data.numpy()[:, 1],\n",
    "    z=x_test.data.numpy()[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=y_test.data.numpy().ravel(),\n",
    "        colorscale='viridis',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set',\n",
    "    text = [\"Density: {}\".format(x) for x in y_test.data.numpy().ravel()]\n",
    "\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "        aspectmode='data',\n",
    "    ),\n",
    ")\n",
    "fig.write_html('tmp.html', auto_open=True)\n",
    "#fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_15680\\4153829123.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_15680\\4153829123.py:23: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\23478671\\AppData\\Local\\Temp\\ipykernel_15680\\4153829123.py:31: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Iteration 0, MSE: 0.0249\n",
      "- Iteration 100, MSE: 0.0033\n",
      "- Iteration 200, MSE: 0.0032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23478671\\Github\\PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation\\Paper 3 PhD BNNs for multivariate predictions\\NN 3D full deposit.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#W3sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m cost\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#W3sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#W3sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m pre_train \u001b[39m=\u001b[39m model(x_train)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#W3sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m mse_train \u001b[39m=\u001b[39m mse_loss(pre_train, y_train)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/23478671/Github/PhD-Thesis---Incorporating-Deep-Learning-into-Statistical-Models-for-Spatial-Interpolation/Paper%203%20PhD%20BNNs%20for%20multivariate%20predictions/NN%203D%20full%20deposit.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(mse_train\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\modules\\activation.py:102\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\23478671\\Anaconda3\\envs\\geostatistics\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mineral = 'Density_gcm3'\n",
    "two_composite_1mineral = two_composite_filtered.loc[:,[\"Name\", 'X', 'Y', 'Z', mineral]]\n",
    "deposit_data = two_composite_1mineral.dropna(subset=[mineral])\n",
    "    \n",
    "# Define the columns to normalize\n",
    "columns_to_normalize = ['X', 'Y', 'Z']  # Add all columns you want to normalize\n",
    "\n",
    "min_values = deposit_data[columns_to_normalize].min()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = deposit_data[column] - min_values[column]\n",
    "\n",
    "# Calculate the minimum and maximum values from the entire dataset\n",
    "min_values = deposit_data[columns_to_normalize].min().min()\n",
    "max_values = deposit_data[columns_to_normalize].max().max()\n",
    "\n",
    "# Scale the data to (0, 1) using the calculated minimum and maximum values\n",
    "for column in columns_to_normalize:\n",
    "    deposit_data[column] = (deposit_data[column] - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Fit the scaler to your data and transform the specified columns\n",
    "deposit_data.loc[:, [mineral]] = scaler.fit_transform(deposit_data.loc[:, [mineral]])\n",
    "\n",
    "x = deposit_data[['X', 'Y', 'Z']].values  # Use X, Y, and Z coordinates\n",
    "y = deposit_data[mineral].values[:, np.newaxis]  # Keep mineral as the output\n",
    "x = x.reshape(len(deposit_data), 3)\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n",
    "x = x.to(torch.float32)\n",
    "y = y.to(torch.float32)\n",
    "\n",
    "# Determine the size of the test set (e.g., 20% of the data)\n",
    "test_size = int(0.2 * len(x))\n",
    "\n",
    "# Generate random indices for the test set\n",
    "test_indices = np.random.choice(len(x), size=test_size, replace=False)\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "x_train = x[np.setdiff1d(np.arange(len(x)), test_indices)]\n",
    "y_train = y[np.setdiff1d(np.arange(len(y)), test_indices)]\n",
    "\n",
    "x_test = x[np.sort(test_indices)]\n",
    "y_test = y[np.sort(test_indices)]\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(in_features=3, out_features=2000),  \n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(in_features=2000, out_features=1)\n",
    "# )\n",
    "\n",
    "# mse_loss = nn.MSELoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# for step in range(400):\n",
    "#     pre = model(x_train)\n",
    "#     mse = mse_loss(pre, y_train)\n",
    "#     cost = mse \n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     cost.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if step % 100 == 0:\n",
    "#         print('- Iteration %d, MSE : %2.3f' % (step, mse.item()))\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=3, out_features=50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=50, out_features=1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "#Apparently lr=0.005 is better than 0.01 and than 0.001: quicker and better convergence\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "train_losses = []  # To store training losses during training\n",
    "test_losses = []   # To store test losses during training\n",
    "\n",
    "for step in range(10001):\n",
    "    pre = model(x_train)\n",
    "    mse = mse_loss(pre, y_train)\n",
    "    cost = mse\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pre_train = model(x_train)\n",
    "    mse_train = mse_loss(pre_train, y_train)\n",
    "    train_losses.append(mse_train.item())\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pre_test = model(x_test)\n",
    "    mse_test = mse_loss(pre_test, y_test)\n",
    "    test_losses.append(mse_test.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f'- Iteration {step}, MSE: {mse.item():.4f}')\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.2 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "#plt.ylim(0, 0.5)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.5 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create a plot showing only values under 0.05 on the y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training', color='blue')\n",
    "plt.plot(test_losses, label='Test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, 0.004)  # Set the y-axis limit to filter values under 0.05\n",
    "plt.legend()\n",
    "plt.title('Training and Test Errors Under 0.025 MSE')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ... (previous code for data preprocessing)\n",
    "\n",
    "# Define a grid of points for prediction (including X, Y, and Z)\n",
    "x_grid = np.linspace(x[:, 0].min(), x[:, 0].max(), 50)\n",
    "y_grid = np.linspace(x[:, 1].min(), x[:, 1].max(), 50)\n",
    "z_grid = np.linspace(x[:, 2].min(), x[:, 2].max(), 50)\n",
    "xyz_grid = np.array(np.meshgrid(x_grid, y_grid, z_grid)).T.reshape(-1, 3)\n",
    "\n",
    "# Make predictions for the grid\n",
    "predictions = model(torch.tensor(xyz_grid, dtype=torch.float32))\n",
    "\n",
    "# Reshape the predictions to match the grid shape\n",
    "predictions = predictions.data.numpy().reshape(50, 50, 50)\n",
    "\n",
    "# Create a 3D surface plot using Plotly\n",
    "\n",
    "# Pool the values from predictions_hole and y_hole\n",
    "pooled_values = np.concatenate([predictions.ravel(), y_test.data.numpy()[:, 0]])\n",
    "\n",
    "# Determine the minimum and maximum values for the color mapping\n",
    "vmin = np.min(pooled_values)\n",
    "vmax = np.max(pooled_values)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "    x=xyz_grid[:,0],\n",
    "    y=xyz_grid[:,1],\n",
    "    z=xyz_grid[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=predictions.ravel(),\n",
    "        colorscale='viridis',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set',\n",
    "    text = [\"Density: {}\".format(x) for x in predictions.ravel() ]\n",
    "\n",
    ")])\n",
    "\n",
    "\n",
    "# Add a scatter plot for test data points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x_test.data.numpy()[:, 0],\n",
    "    y=x_test.data.numpy()[:, 1],\n",
    "    z=x_test.data.numpy()[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=y_test.data.numpy().ravel(),\n",
    "        colorscale='viridis',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set',\n",
    "    text = [\"Density: {}\".format(x) for x in y_test.data.numpy().ravel()]\n",
    "\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "        aspectmode='data',\n",
    "    ),\n",
    ")\n",
    "fig.write_html('tmp.html', auto_open=True)\n",
    "#fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool the values from predictions_hole and y_hole\n",
    "pooled_values = np.concatenate([predictions.ravel(), y_test.data.numpy()[:, 0]])\n",
    "\n",
    "# Determine the minimum and maximum values for the color mapping\n",
    "vmin = np.min(pooled_values)\n",
    "vmax = np.max(pooled_values)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "    x=xyz_grid[:,0],\n",
    "    y=xyz_grid[:,1],\n",
    "    z=xyz_grid[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=predictions.ravel(),\n",
    "        colorscale='Hot',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set'\n",
    ")])\n",
    "\n",
    "\n",
    "# Add a scatter plot for test data points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x_test.data.numpy()[:, 0],\n",
    "    y=x_test.data.numpy()[:, 1],\n",
    "    z=x_test.data.numpy()[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=y_test.data.numpy().ravel(),\n",
    "        colorscale='Hot',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set'\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "        aspectmode='data',\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.linspace(x[:, 0].min(), x[:, 0].max(), 60)\n",
    "y_grid = np.linspace(x[:, 1].min(), x[:, 1].max(), 6)\n",
    "z_grid = np.linspace(x[:, 2].min(), x[:, 2].max(), 100)\n",
    "xyz_grid = np.array(np.meshgrid(x_grid, y_grid, z_grid)).T.reshape(-1, 3)\n",
    "\n",
    "# Make predictions for the grid\n",
    "predictions = model(torch.tensor(xyz_grid, dtype=torch.float32))\n",
    "\n",
    "# Reshape the predictions to match the grid shape\n",
    "predictions = predictions.data.numpy().reshape(60, 6, 100)\n",
    "\n",
    "pooled_values = np.concatenate([predictions.ravel(), y_test.data.numpy()[:, 0], y_train.data.numpy()[:, 0]])\n",
    "\n",
    "# Determine the minimum and maximum values for the color mapping\n",
    "vmin = np.min(pooled_values)\n",
    "vmax = np.max(pooled_values)\n",
    "\n",
    "step_titles = [\"Predictions\", \"Test Set\", \"Train Set\"]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "    x=xyz_grid[:,0],\n",
    "    y=xyz_grid[:,1],\n",
    "    z=xyz_grid[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=predictions.ravel(),\n",
    "        colorscale='Hot',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Preds',\n",
    "    text = [\"Density: {}\".format(x) for x in predictions.ravel() ]\n",
    ")])\n",
    "\n",
    "\n",
    "# Add a scatter plot for test data points\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x.data.numpy()[:, 0],\n",
    "    y=x.data.numpy()[:, 1],\n",
    "    z=x.data.numpy()[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=y.data.numpy().ravel(),\n",
    "        colorscale='Hot',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set',\n",
    "    text = [\"Density: {}\".format(x) for x in y_test.data.numpy().ravel()]\n",
    "\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=x_test.data.numpy()[:, 0],\n",
    "    y=x_test.data.numpy()[:, 1],\n",
    "    z=x_test.data.numpy()[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=y_test.data.numpy().ravel(),\n",
    "        colorscale='Hot',  # Adjust the color scale\n",
    "        colorbar=dict(title=mineral),\n",
    "        opacity=0.7,\n",
    "        cmax=vmax,\n",
    "        cmin=vmin,\n",
    "    ),\n",
    "    name='Test set',\n",
    "    text = [\"Density: {}\".format(x) for x in y_test.data.numpy().ravel()]\n",
    "\n",
    "))\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "for i in range(len(fig.data)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig.data)},\n",
    "              {\"title\": \"Slider switched to step: \" + step_titles[i]}],  # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Frequency: \"},\n",
    "    pad={\"t\": 0},\n",
    "    steps=steps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "        aspectmode='data',\n",
    "    ),\n",
    ")\n",
    "fig.write_html('tmp.html', auto_open=True)\n",
    "#fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
